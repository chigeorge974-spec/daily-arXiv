{"id": "2602.16744", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.16744", "abs": "https://arxiv.org/abs/2602.16744", "authors": ["Takuro Kato", "Mitsuharu Morisawa"], "title": "ICP-Based Pallet Tracking for Unloading on Inclined Surfaces by Autonomous Forklifts", "comment": "Accepted and published in IEEE/SICE SII 2024", "summary": "This paper proposes a control method for autonomous forklifts to unload pallets on inclined surfaces, enabling the fork to be withdrawn without dragging the pallets. The proposed method applies the Iterative Closest Point (ICP) algorithm to point clouds measured from the upper region of the pallet and thereby tracks the relative position and attitude angle difference between the pallet and the fork during the unloading operation in real-time. According to the tracking result, the fork is aligned parallel to the target surface. After the fork is aligned, it is possible to complete the unloading process by withdrawing the fork along the tilt, preventing any dragging of the pallet. The effectiveness of the proposed method is verified through dynamic simulations and experiments using a real forklift that replicate unloading operations onto the inclined bed of a truck.", "AI": {"tldr": "Proposes ICP-based control for autonomous forklifts to unload pallets on inclined surfaces without dragging by tracking pallet-fork alignment and withdrawing along tilt.", "motivation": "Autonomous forklifts need to unload pallets onto inclined surfaces (like truck beds) without dragging them, which requires precise alignment between fork and pallet during withdrawal.", "method": "Uses Iterative Closest Point (ICP) algorithm on point clouds from pallet's upper region to track relative position and attitude angle difference in real-time, then aligns fork parallel to target surface and withdraws along tilt.", "result": "Effectiveness verified through dynamic simulations and real forklift experiments replicating unloading operations onto inclined truck beds.", "conclusion": "The proposed ICP-based control method enables successful pallet unloading on inclined surfaces without dragging by maintaining proper fork-pallet alignment during withdrawal."}}
{"id": "2602.16758", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.16758", "abs": "https://arxiv.org/abs/2602.16758", "authors": ["Sina Akhbari", "Mehran Mahboubkhah"], "title": "Smooth trajectory generation and hybrid B-splines-Quaternions based tool path interpolation for a 3T1R parallel kinematic milling robot", "comment": "30 pages, 17 figures, published in Elsevier Precision Engineering (https://www.sciencedirect.com/science/article/abs/pii/S0141635925001266)", "summary": "This paper presents a smooth trajectory generation method for a four-degree-of-freedom parallel kinematic milling robot. The proposed approach integrates B-spline and Quaternion interpolation techniques to manage decoupled position and orientation data points. The synchronization of orientation and arc-length-parameterized position data is achieved through the fitting of smooth piece-wise Bezier curves, which describe the non-linear relationship between path length and tool orientation, solved via sequential quadratic programming. By leveraging the convex hull properties of Bezier curves, the method ensures spatial and temporal separation constraints for multi-agent trajectory generation. Unit quaternions are employed for orientation interpolation, providing a robust and efficient representation that avoids gimbal lock and facilitates smooth, continuous rotation. Modifier polynomials are used for position interpolation. Temporal trajectories are optimized using minimum jerk, time-optimal piece-wise Bezier curves in two stages: task space followed by joint space, implemented on a low-cost microcontroller. Experimental results demonstrate that the proposed method offers enhanced accuracy, reduced velocity fluctuations, and computational efficiency compared to conventional interpolation methods.", "AI": {"tldr": "A smooth trajectory generation method for a 4-DOF parallel kinematic milling robot using B-spline and Quaternion interpolation with Bezier curve synchronization and minimum jerk optimization.", "motivation": "To develop an efficient trajectory generation method for parallel kinematic milling robots that handles decoupled position and orientation data while ensuring smooth motion, avoiding gimbal lock, and meeting spatial/temporal constraints for multi-agent applications.", "method": "Integrates B-spline and Quaternion interpolation for decoupled position/orientation data. Uses smooth piece-wise Bezier curves to synchronize orientation with arc-length-parameterized position via sequential quadratic programming. Employs unit quaternions for orientation interpolation and modifier polynomials for position interpolation. Optimizes temporal trajectories using minimum jerk, time-optimal piece-wise Bezier curves in two stages (task space then joint space) on a low-cost microcontroller.", "result": "Experimental results show enhanced accuracy, reduced velocity fluctuations, and computational efficiency compared to conventional interpolation methods.", "conclusion": "The proposed method successfully generates smooth trajectories for 4-DOF parallel kinematic milling robots by effectively integrating B-spline and Quaternion interpolation with Bezier curve synchronization and minimum jerk optimization, achieving improved performance metrics."}}
{"id": "2602.16825", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.16825", "abs": "https://arxiv.org/abs/2602.16825", "authors": ["Ahmad Ahmad", "Shuo Liu", "Roberto Tron", "Calin Belta"], "title": "RRT$^\u03b7$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness", "comment": null, "summary": "Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration.\n  We propose RRT$^\u03b7$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.", "AI": {"tldr": "RRT$^\u03b7$: A sampling-based motion planning framework that integrates Arithmetic-Geometric Mean robustness for STL specifications, improving exploration efficiency in complex multi-constraint scenarios.", "motivation": "Traditional STL-based planning uses min-max robustness measures that create non-smooth optimization landscapes with sharp decision boundaries, hindering efficient tree exploration in sampling-based motion planning.", "method": "Proposes RRT$^\u03b7$ framework with: (1) AGM robustness interval semantics for partial trajectory reasoning, (2) efficient incremental monitoring algorithm for interval computation, and (3) enhanced Direction of Increasing Satisfaction vectors using Fulfillment Priority Logic for objective composition.", "result": "The framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining probabilistic completeness and asymptotic optimality of RRT$^\\ast$. Validated on three robotic systems (double integrator, unicycle, 7-DOF arm) showing superior performance over traditional STL robustness-based planners.", "conclusion": "RRT$^\u03b7$ effectively addresses limitations of traditional STL robustness measures by using AGM robustness, enabling more efficient exploration in complex multi-constraint scenarios with limited guidance signals."}}
{"id": "2602.16846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.16846", "abs": "https://arxiv.org/abs/2602.16846", "authors": ["Xili Yi", "Ying Xing", "Zachary Manchester", "Nima Fazeli"], "title": "Sound of Touch: Active Acoustic Tactile Sensing via String Vibrations", "comment": "12 pages, 10 figures", "summary": "Distributed tactile sensing remains difficult to scale over large areas: dense sensor arrays increase wiring, cost, and fragility, while many alternatives provide limited coverage or miss fast interaction dynamics. We present Sound of Touch, an active acoustic tactile-sensing methodology that uses vibrating tensioned strings as sensing elements. The string is continuously excited electromagnetically, and a small number of pickups (contact microphones) observe spectral changes induced by contact. From short-duration audio signals, our system estimates contact location and normal force, and detects slip. To guide design and interpret the sensing mechanism, we derive a physics-based string-vibration simulator that predicts how contact position and force shift vibration modes. Experiments demonstrate millimeter-scale localization, reliable force estimation, and real-time slip detection. Our contributions are: (i) a lightweight, scalable string-based tactile sensing hardware concept for instrumenting extended robot surfaces; (ii) a physics-grounded simulation and analysis tool for contact-induced spectral shifts; and (iii) a real-time inference pipeline that maps vibration measurements to contact state.", "AI": {"tldr": "Sound of Touch: A scalable tactile sensing system using vibrating tensioned strings and acoustic analysis to detect contact location, force, and slip in real-time.", "motivation": "Distributed tactile sensing is difficult to scale over large areas due to wiring complexity, cost, fragility of dense sensor arrays, and limited coverage/response time of alternatives.", "method": "Uses vibrating tensioned strings as sensing elements with electromagnetic excitation and contact microphone pickups; analyzes spectral changes in audio signals; includes physics-based string-vibration simulator for contact prediction; implements real-time inference pipeline mapping vibrations to contact state.", "result": "Demonstrates millimeter-scale localization, reliable force estimation, and real-time slip detection; provides scalable hardware concept for instrumenting extended robot surfaces.", "conclusion": "Presents a scalable, lightweight string-based tactile sensing methodology with physics-grounded simulation and real-time inference capabilities for large-area robotic applications."}}
{"id": "2602.16714", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16714", "abs": "https://arxiv.org/abs/2602.16714", "authors": ["Renato Marcelo", "Ana Rodrigues", "Cristiana Palmela Pereira", "Ant\u00f3nio Figueiras", "Rui Santos", "Jos\u00e9 Rui Figueira", "Alexandre P Francisco", "C\u00e1tia Vaz"], "title": "AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment", "comment": null, "summary": "Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the most reliable biological approaches for adolescents and young adults, but current practices are challenged by methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal information systems. These limitations hinder transparency and reproducibility, amplified by the increasing adoption of AI- based methods. The AIdentifyAGE ontology is domain-specific and provides a standardized, semantically coherent framework, encompassing both manual and AI-assisted forensic dental age assessment workflows, and enabling traceable linkage between observations, methods, reference data, and reported outcomes. It models the complete medico-legal workflow, integrating judicial context, individual-level information, forensic examination data, dental developmental assessment methods, radiographic imaging, statistical reference studies, and AI-based estimation methods. It is being developed together with domain experts, and it builds on upper and established biomedical, dental, and machine learning ontologies, ensuring interoperability, extensibility, and compliance with FAIR principles. The AIdentifyAGE ontology is a fundamental step to enhance consistency, transparency, and explainability, establishing a robust foundation for ontology-driven decision support systems in medico-legal and judicial contexts.", "AI": {"tldr": "AIdentifyAGE ontology provides standardized semantic framework for forensic dental age assessment, addressing methodological heterogeneity and enabling traceable linkage between observations, methods, and outcomes in medico-legal workflows.", "motivation": "Current dental age assessment practices suffer from methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal systems, hindering transparency and reproducibility, especially with increasing AI adoption.", "method": "Developed with domain experts, the AIdentifyAGE ontology builds on upper and established biomedical, dental, and machine learning ontologies to create a standardized, semantically coherent framework that models complete medico-legal workflows including judicial context, individual information, forensic examination data, dental development assessment methods, radiographic imaging, reference studies, and AI-based estimation methods.", "result": "The ontology provides a standardized framework that enables traceable linkage between observations, methods, reference data, and reported outcomes, ensuring interoperability, extensibility, and compliance with FAIR principles.", "conclusion": "AIdentifyAGE ontology enhances consistency, transparency, and explainability in forensic dental age assessment, establishing a foundation for ontology-driven decision support systems in medico-legal and judicial contexts."}}
{"id": "2602.16861", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16861", "abs": "https://arxiv.org/abs/2602.16861", "authors": ["EunJeong Cheon", "Do Yeon Shin"], "title": "\"Hello, I'm Delivering. Let Me Pass By\": Navigating Public Pathways with Walk-along with Robots in Crowded City Streets", "comment": null, "summary": "As the presence of autonomous robots in public spaces increases-whether navigating campus walkways or neighborhood sidewalks-understanding how to carefully study these robots becomes critical. While HRI research has conducted field studies in public spaces, these are often limited to controlled experiments with prototype robots or structured observational methods, such as the Wizard of Oz technique. However, the autonomous mobile robots we encounter today, particularly delivery robots, operate beyond the control of researchers, navigating dynamic routes and unpredictable environments. To address this challenge, a more deliberate approach is required. Drawing inspiration from public realm ethnography in urban studies, geography, and sociology, this paper proposes the Walk-Along with Robots (WawR) methodology. We outline the key features of this method, the steps we applied in our study, the unique insights it offers, and the ways it can be evaluated. We hope this paper stimulates further discussion on research methodologies for studying autonomous robots in public spaces.", "AI": {"tldr": "Proposes Walk-Along with Robots (WawR) methodology for studying autonomous mobile robots in public spaces, drawing from public realm ethnography to address limitations of controlled experiments.", "motivation": "Current HRI field studies in public spaces are limited to controlled experiments with prototype robots or structured methods like Wizard of Oz, but autonomous mobile robots (especially delivery robots) operate beyond researcher control in dynamic, unpredictable environments, requiring a more deliberate approach.", "method": "Walk-Along with Robots (WawR) methodology, inspired by public realm ethnography from urban studies, geography, and sociology. The paper outlines key features, application steps, unique insights offered, and evaluation methods.", "result": "The paper presents a methodological framework rather than empirical results. It proposes WawR as an approach to study autonomous robots operating in public spaces beyond researcher control.", "conclusion": "WawR methodology addresses the challenge of studying autonomous robots in public spaces and aims to stimulate further discussion on research methodologies for this domain."}}
{"id": "2602.16863", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16863", "abs": "https://arxiv.org/abs/2602.16863", "authors": ["Kushal Kedia", "Tyler Ga Wei Lum", "Jeannette Bohg", "C. Karen Liu"], "title": "SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation", "comment": null, "summary": "The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.", "AI": {"tldr": "SimToolReal: A sim-to-real RL approach for general dexterous tool manipulation using procedurally generated tool-like objects and universal goal training, achieving strong zero-shot performance across diverse real-world tools.", "motivation": "Tool manipulation is challenging for robots due to requirements for grasping thin objects, in-hand rotations, and forceful interactions. Teleoperation data collection is difficult, and existing sim-to-real RL approaches require substantial engineering effort for object modeling and reward tuning per task.", "method": "Procedurally generate large variety of tool-like object primitives in simulation. Train a single RL policy with universal goal of manipulating each object to random goal poses. This enables generalization without object or task-specific training at test time.", "result": "Outperforms prior retargeting and fixed-grasp methods by 37%. Matches performance of specialist RL policies trained on specific target objects and tasks. Achieves strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.", "conclusion": "SimToolReal demonstrates effective generalization of sim-to-real RL policies for tool manipulation, enabling zero-shot performance across diverse real-world tools without task-specific training or engineering effort."}}
{"id": "2602.16716", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.16716", "abs": "https://arxiv.org/abs/2602.16716", "authors": ["Song-Ju Kim"], "title": "Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence", "comment": "This paper addresses contextuality from a representation-theoretic and information-theoretic perspective in adaptive systems. It is conceptually and technically distinct from the authors' earlier arXiv works (QTOW/QTOW2), which pursue different formulations of contextuality", "summary": "Adaptive systems often operate across multiple contexts while reusing a fixed internal state space due to constraints on memory, representation, or physical resources. Such single-state reuse is ubiquitous in natural and artificial intelligence, yet its fundamental representational consequences remain poorly understood. We show that contextuality is not a peculiarity of quantum mechanics, but an inevitable consequence of single-state reuse in classical probabilistic representations. Modeling contexts as interventions acting on a shared internal state, we prove that any classical model reproducing contextual outcome statistics must incur an irreducible information-theoretic cost: dependence on context cannot be mediated solely through the internal state. We provide a minimal constructive example that explicitly realizes this cost and clarifies its operational meaning. We further explain how nonclassical probabilistic frameworks avoid this obstruction by relaxing the assumption of a single global joint probability space, without invoking quantum dynamics or Hilbert space structure. Our results identify contextuality as a general representational constraint on adaptive intelligence, independent of physical implementation.", "AI": {"tldr": "Contextuality emerges from single-state reuse in classical probabilistic systems, creating irreducible information-theoretic costs that nonclassical frameworks avoid by relaxing global joint probability assumptions.", "motivation": "To understand the fundamental representational consequences of single-state reuse in adaptive systems, which is ubiquitous in natural and artificial intelligence but poorly understood in terms of contextuality.", "method": "Model contexts as interventions acting on a shared internal state, prove that classical models reproducing contextual outcome statistics incur irreducible information-theoretic costs, provide minimal constructive examples, and analyze how nonclassical frameworks avoid this obstruction.", "result": "Contextuality is not exclusive to quantum mechanics but inevitable in classical probabilistic representations with single-state reuse; classical models must incur irreducible information-theoretic costs where context dependence cannot be mediated solely through internal state.", "conclusion": "Contextuality represents a general representational constraint on adaptive intelligence independent of physical implementation, arising from single-state reuse rather than quantum dynamics."}}
{"id": "2602.16870", "categories": ["cs.RO", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.16870", "abs": "https://arxiv.org/abs/2602.16870", "authors": ["Daniil Lisus", "Katya M. Papais", "Cedric Le Gentil", "Elliot Preston-Krebs", "Andrew Lambert", "Keith Y. K. Leung", "Timothy D. Barfoot"], "title": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads", "comment": "23 pages, 15 figures, 12 tables, submitted to The International Journal of Robotics Research (IJRR)", "summary": "The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomous driving algorithms. Boreas-RT comprises 60 sequences collected over 9 real-world routes, totalling 643 km of driving. Each route is traversed multiple times, enabling evaluation in identical environments under varying traffic and, in some cases, weather conditions. The data collection platform includes a 5MP FLIR Blackfly S camera, a 360 degree Navtech RAS6 Doppler-enabled spinning radar, a 128-channel 360 degree Velodyne Alpha Prime lidar, an Aeva Aeries II FMCW Doppler-enabled lidar, a Silicon Sensing DMU41 inertial measurement unit, and a Dynapar wheel encoder. Centimetre-level ground truth is provided via post-processed Applanix POS LV GNSS-INS data. The dataset includes precise extrinsic and intrinsic calibrations, a publicly available development kit, and a live leaderboard for odometry and metric localization. Benchmark results show that many state-of-the-art odometry and localization algorithms overfit to simple driving environments and degrade significantly on the more challenging Boreas-RT routes. Boreas-RT provides a unified dataset for evaluating multi-modal algorithms across diverse road conditions. The dataset, leaderboard, and development kit are available at www.boreas.utias.utoronto.ca.", "AI": {"tldr": "Boreas-RT extends the Boreas dataset with 643 km of driving data across 9 diverse routes, featuring multi-modal sensors and centimeter-level ground truth to benchmark odometry and localization algorithms in challenging real-world conditions.", "motivation": "Existing autonomous driving datasets often lack diversity in road conditions and environments, causing state-of-the-art odometry and localization algorithms to overfit to simple scenarios and degrade in more challenging real-world settings.", "method": "Collection of 60 sequences over 9 diverse real-world routes using a multi-sensor platform including cameras, Doppler-enabled radar, 360\u00b0 lidar, FMCW Doppler lidar, IMU, and wheel encoders, with centimeter-level ground truth from post-processed GNSS-INS data.", "result": "Benchmark results demonstrate that many state-of-the-art odometry and localization algorithms significantly degrade on the challenging Boreas-RT routes, revealing overfitting to simpler environments present in existing datasets.", "conclusion": "Boreas-RT provides a comprehensive, diverse dataset for evaluating multi-modal autonomous driving algorithms, exposing limitations of current methods and enabling development of more robust systems through its unified benchmark platform."}}
{"id": "2602.16727", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16727", "abs": "https://arxiv.org/abs/2602.16727", "authors": ["Hua Yan", "Heng Tan", "Yingxue Zhang", "Yu Yang"], "title": "Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation", "comment": null, "summary": "Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost limits scalability. To address this, we design a mobility-aware cache framework named MobCache that leverages reconstructible caches to enable efficient large-scale human mobility simulations. It consists of: (1) a reasoning component that encodes each reasoning step as a latent-space embedding and uses a latent-space evaluator to enable the reuse and recombination of reasoning steps; and (2) a decoding component that employs a lightweight decoder trained with mobility law-constrained distillation to translate latent-space reasoning chains into natural language, thereby improving simulation efficiency while maintaining fidelity. Experiments show that MobCache significantly improves efficiency across multiple dimensions while maintaining performance comparable to state-of-the-art LLM-based methods.", "AI": {"tldr": "MobCache: A mobility-aware cache framework using reconstructible caches and latent-space reasoning to enable efficient large-scale human mobility simulations with LLMs while maintaining fidelity.", "motivation": "Large-scale human mobility simulation is crucial for urban planning, epidemiology, and transportation analysis, but existing LLM-based approaches suffer from high computational costs that limit scalability.", "method": "MobCache consists of two components: (1) a reasoning component that encodes reasoning steps as latent-space embeddings with a latent-space evaluator for reuse and recombination, and (2) a decoding component with a lightweight decoder trained using mobility law-constrained distillation to translate latent reasoning chains into natural language.", "result": "Experiments demonstrate that MobCache significantly improves efficiency across multiple dimensions while maintaining performance comparable to state-of-the-art LLM-based methods.", "conclusion": "The proposed MobCache framework enables efficient large-scale human mobility simulations by leveraging reconstructible caches and latent-space reasoning, addressing the scalability limitations of existing LLM-based approaches while preserving simulation fidelity."}}
{"id": "2602.16898", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16898", "abs": "https://arxiv.org/abs/2602.16898", "authors": ["Iman Ahmadi", "Mehrshad Taji", "Arad Mahdinezhad Kashani", "AmirHossein Jadidi", "Saina Kashani", "Babak Khalaj"], "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation", "comment": null, "summary": "Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step.Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.", "code_url": "https://github.com/iman1234ahmadi/MALLVI", "code_stars": 0, "code_last_update": "2026-02-17", "AI": {"tldr": "MALLVi is a multi-agent LLM/VLM framework for closed-loop robotic manipulation that coordinates specialized agents for perception, localization, reasoning, and planning with environmental feedback, improving zero-shot task success rates.", "motivation": "Prior LLM-based robotic manipulation approaches are fragile in dynamic settings due to open-loop operation without robust environmental feedback, reliance on specialized models/fine-tuning, and lack of closed-loop control.", "method": "Multi-agent framework with specialized agents: Decomposer (perception), Localizer (object localization), Thinker (reasoning), Reflector (high-level planning/error recovery), and optional Descriptor (visual memory). Uses closed-loop feedback where VLM evaluates execution results and decides next steps, with targeted error recovery by reactivating only relevant agents.", "result": "Experiments in simulation and real-world settings demonstrate that iterative closed-loop multi-agent coordination improves generalization and increases success rates in zero-shot manipulation tasks compared to prior approaches.", "conclusion": "MALLVi's multi-agent architecture with closed-loop feedback and targeted error recovery enables more robust robotic manipulation in dynamic environments, addressing limitations of prior open-loop LLM-based approaches."}}
{"id": "2602.16763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16763", "abs": "https://arxiv.org/abs/2602.16763", "authors": ["Mubashara Akhtar", "Anka Reuel", "Prajna Soni", "Sanchit Ahuja", "Pawan Sasanka Ammanamanchi", "Ruchit Rawal", "Vil\u00e9m Zouhar", "Srishti Yadav", "Chenxi Whitehouse", "Dayeon Ki", "Jennifer Mickel", "Leshem Choshen", "Marek \u0160uppa", "Jan Batzner", "Jenny Chim", "Jeba Sania", "Yanan Long", "Hossein A. Rahmani", "Christina Knight", "Yiyang Nan", "Jyoutir Raj", "Yu Fan", "Shubham Singh", "Subramanyam Sahoo", "Eliya Habba", "Usman Gohar", "Siddhesh Pawar", "Robert Scholz", "Arjun Subramonian", "Jingwei Ni", "Mykel Kochenderfer", "Sanmi Koyejo", "Mrinmaya Sachan", "Stella Biderman", "Zeerak Talat", "Avijit Ghosh", "Irene Solaiman"], "title": "When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation", "comment": null, "summary": "Artificial Intelligence (AI) benchmarks play a central role in measuring progress in model development and guiding deployment decisions. However, many benchmarks quickly become saturated, meaning that they can no longer differentiate between the best-performing models, diminishing their long-term value. In this study, we analyze benchmark saturation across 60 Large Language Model (LLM) benchmarks selected from technical reports by major model developers. To identify factors driving saturation, we characterize benchmarks along 14 properties spanning task design, data construction, and evaluation format. We test five hypotheses examining how each property contributes to saturation rates. Our analysis reveals that nearly half of the benchmarks exhibit saturation, with rates increasing as benchmarks age. Notably, hiding test data (i.e., public vs. private) shows no protective effect, while expert-curated benchmarks resist saturation better than crowdsourced ones. Our findings highlight which design choices extend benchmark longevity and inform strategies for more durable evaluation.", "AI": {"tldr": "Analysis of 60 LLM benchmarks reveals nearly half show saturation, with expert-curated benchmarks resisting saturation better than crowdsourced ones, and hidden test data providing no protective effect.", "motivation": "AI benchmarks quickly become saturated, losing their ability to differentiate between top-performing models, which diminishes their long-term value and hampers progress measurement in model development.", "method": "Analyzed 60 LLM benchmarks from major model developers' technical reports, characterized them along 14 properties spanning task design, data construction, and evaluation format, and tested five hypotheses about how each property contributes to saturation rates.", "result": "Nearly half of benchmarks exhibit saturation, with rates increasing as benchmarks age; hiding test data (public vs. private) shows no protective effect; expert-curated benchmarks resist saturation better than crowdsourced ones.", "conclusion": "Benchmark design choices significantly impact longevity, with expert curation being particularly effective against saturation, providing guidance for creating more durable evaluation frameworks."}}
{"id": "2602.16911", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.16911", "abs": "https://arxiv.org/abs/2602.16911", "authors": ["Adrian R\u00f6fer", "Nick Heppert", "Abhinav Valada"], "title": "SparTa: Sparse Graphical Task Models from a Handful of Demonstrations", "comment": "9 pages, 6 figures, under review", "summary": "Learning long-horizon manipulation tasks efficiently is a central challenge in robot learning from demonstration. Unlike recent endeavors that focus on directly learning the task in the action domain, we focus on inferring what the robot should achieve in the task, rather than how to do so. To this end, we represent evolving scene states using a series of graphical object relationships. We propose a demonstration segmentation and pooling approach that extracts a series of manipulation graphs and estimates distributions over object states across task phases. In contrast to prior graph-based methods that capture only partial interactions or short temporal windows, our approach captures complete object interactions spanning from the onset of control to the end of the manipulation. To improve robustness when learning from multiple demonstrations, we additionally perform object matching using pre-trained visual features. In extensive experiments, we evaluate our method's demonstration segmentation accuracy and the utility of learning from multiple demonstrations for finding a desired minimal task model. Finally, we deploy the fitted models both in simulation and on a real robot, demonstrating that the resulting task representations support reliable execution across environments.", "AI": {"tldr": "The paper presents a graph-based approach for learning long-horizon manipulation tasks from demonstrations by inferring what to achieve rather than how, using manipulation graphs that capture complete object interactions across task phases.", "motivation": "Current robot learning from demonstration methods focus on learning actions directly, but the authors argue it's more efficient to infer what the robot should achieve in the task rather than how to do so. They aim to address limitations of prior graph-based methods that capture only partial interactions or short temporal windows.", "method": "The method represents evolving scene states using graphical object relationships. It uses demonstration segmentation and pooling to extract manipulation graphs and estimate distributions over object states across task phases. The approach captures complete object interactions from control onset to manipulation end. For robustness with multiple demonstrations, it performs object matching using pre-trained visual features.", "result": "The method was evaluated on demonstration segmentation accuracy and utility of learning from multiple demonstrations for finding minimal task models. The fitted models were deployed in simulation and on a real robot, showing that the task representations support reliable execution across environments.", "conclusion": "The graph-based approach successfully learns long-horizon manipulation tasks by focusing on inferring task objectives rather than actions, with complete object interaction modeling and robust multi-demonstration learning enabling reliable cross-environment execution."}}
{"id": "2602.16805", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16805", "abs": "https://arxiv.org/abs/2602.16805", "authors": ["Yonatan Gideoni", "Sebastian Risi", "Yarin Gal"], "title": "Simple Baselines are Competitive with Code Evolution", "comment": null, "summary": "Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophisticated methods in all three. By analyzing these results we find various shortcomings in how code evolution is both developed and used. For the mathematical bounds, a problem's search space and domain knowledge in the prompt are chiefly what dictate a search's performance ceiling and efficiency, with the code evolution pipeline being secondary. Thus, the primary challenge in finding improved bounds is designing good search spaces, which is done by domain experts, and not the search itself. When designing agentic scaffolds we find that high variance in the scaffolds coupled with small datasets leads to suboptimal scaffolds being selected, resulting in hand-designed majority vote scaffolds performing best. We propose better evaluation methods that reduce evaluation stochasticity while keeping the code evolution economically feasible. We finish with a discussion of avenues and best practices to enable more rigorous code evolution in future work.", "AI": {"tldr": "Simple baselines match or exceed sophisticated code evolution methods across mathematical bounds, agentic scaffolds, and ML competitions, revealing methodological shortcomings in current code evolution research.", "motivation": "Code evolution techniques using LLMs show impressive performance but often lack comparison to simpler baselines, raising questions about their actual effectiveness and methodological rigor.", "method": "Tested two simple baselines across three domains: mathematical bounds, agentic scaffolds, and machine learning competitions, comparing them against more sophisticated code evolution methods.", "result": "Simple baselines matched or exceeded sophisticated methods in all three domains. For mathematical bounds, search space design and domain knowledge were more important than the evolution pipeline. For agentic scaffolds, high variance and small datasets led to suboptimal selection, with hand-designed majority vote performing best.", "conclusion": "Current code evolution research has methodological shortcomings; the primary challenge is designing good search spaces rather than the search itself. The paper proposes better evaluation methods and discusses best practices for more rigorous code evolution research."}}
{"id": "2602.17101", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17101", "abs": "https://arxiv.org/abs/2602.17101", "authors": ["Varun Burde", "Pavel Burget", "Torsten Sattler"], "title": "Benchmarking the Effects of Object Pose Estimation and Reconstruction on Robotic Grasping Success", "comment": null, "summary": "3D reconstruction serves as the foundational layer for numerous robotic perception tasks, including 6D object pose estimation and grasp pose generation. Modern 3D reconstruction methods for objects can produce visually and geometrically impressive meshes from multi-view images, yet standard geometric evaluations do not reflect how reconstruction quality influences downstream tasks such as robotic manipulation performance. This paper addresses this gap by introducing a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on their functional efficacy in grasping. We analyze the impact of model fidelity by generating grasps on various reconstructed 3D meshes and executing them on the ground-truth model, simulating how grasp poses generated with an imperfect model affect interaction with the real object. This assesses the combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction. Our results show that reconstruction artifacts significantly decrease the number of grasp pose candidates but have a negligible effect on grasping performance given an accurately estimated pose. Our results also reveal that the relationship between grasp success and pose error is dominated by spatial error, and even a simple translation error provides insight into the success of the grasping pose of symmetric objects. This work provides insight into how perception systems relate to object manipulation using robots.", "AI": {"tldr": "The paper introduces a physics-based benchmark to evaluate 3D reconstruction quality and 6D pose estimation based on their functional impact on robotic grasping performance, revealing that reconstruction artifacts reduce grasp candidates but don't significantly affect grasping success with accurate pose estimation.", "motivation": "Current 3D reconstruction methods produce visually impressive meshes, but standard geometric evaluations don't reflect how reconstruction quality affects downstream robotic manipulation tasks like grasping. There's a gap in understanding how perception system errors translate to functional performance in robotics.", "method": "The authors create a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on grasping efficacy. They generate grasps on various reconstructed meshes and execute them on ground-truth models in simulation, assessing combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction.", "result": "Reconstruction artifacts significantly decrease the number of grasp pose candidates but have negligible effect on grasping performance when pose is accurately estimated. The relationship between grasp success and pose error is dominated by spatial error, and even simple translation error provides insight into grasping success for symmetric objects.", "conclusion": "This work provides insight into how perception systems relate to object manipulation using robots, establishing a functional benchmark that connects 3D reconstruction quality and pose estimation accuracy to actual robotic grasping performance."}}
{"id": "2602.16807", "categories": ["cs.AI", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.16807", "abs": "https://arxiv.org/abs/2602.16807", "authors": ["Duncan Soiffer", "Nathaniel Itty", "Christopher D. Rosin", "Blake Bruell", "Mason DiCicco", "G\u00e1bor N. S\u00e1rk\u00f6zy", "Ryan Offstein", "Daniel Reichman"], "title": "Improved Upper Bounds for Slicing the Hypercube", "comment": null, "summary": "A collection of hyperplanes $\\mathcal{H}$ slices all edges of the $n$-dimensional hypercube $Q_n$ with vertex set $\\{-1,1\\}^n$ if, for every edge $e$ in the hypercube, there exists a hyperplane in $\\mathcal{H}$ intersecting $e$ in its interior. Let $S(n)$ be the minimum number of hyperplanes needed to slice $Q_n$. We prove that $S(n) \\leq \\lceil \\frac{4n}{5} \\rceil$, except when $n$ is an odd multiple of $5$, in which case $S(n) \\leq \\frac{4n}{5} +1$. This improves upon the previously known upper bound of $S(n) \\leq \\lceil\\frac{5n}{6} \\rceil$ due to Paterson reported in 1971. We also obtain new lower bounds on the maximum number of edges in $Q_n$ that can be sliced using $k<n$ hyperplanes. We prove the improved upper bound on $S(n)$ by constructing $8$ hyperplanes slicing $Q_{10}$ aided by the recently introduced CPro1: an automatic tool that uses reasoning LLMs coupled with automated hyperparameter tuning to create search algorithms for the discovery of mathematical constructions.", "AI": {"tldr": "The paper improves the upper bound for slicing all edges of an n-dimensional hypercube with hyperplanes, reducing it from \u23085n/6\u2309 to \u23084n/5\u2309 (with a slight adjustment for odd multiples of 5), and introduces new lower bounds for partial slicing.", "motivation": "The problem of determining the minimum number of hyperplanes needed to slice all edges of an n-dimensional hypercube (Q_n) is a classical combinatorial geometry problem. Previous bounds date back to Paterson's 1971 result of S(n) \u2264 \u23085n/6\u2309, leaving room for improvement. The authors aim to establish tighter bounds on this fundamental problem.", "method": "The authors construct 8 hyperplanes that slice Q_10, which serves as a key building block. They use a novel automated approach called CPro1, which combines reasoning large language models with automated hyperparameter tuning to create search algorithms for discovering mathematical constructions. This computational approach helps find the hyperplane configurations that achieve the improved bounds.", "result": "The main result proves that S(n) \u2264 \u23084n/5\u2309, except when n is an odd multiple of 5, where S(n) \u2264 4n/5 + 1. This improves upon Paterson's 1971 bound of S(n) \u2264 \u23085n/6\u2309. The paper also establishes new lower bounds on the maximum number of edges in Q_n that can be sliced using k < n hyperplanes.", "conclusion": "The paper demonstrates significant progress on the hypercube edge slicing problem, achieving improved upper bounds through computational methods. The use of CPro1, an automated tool combining LLMs with hyperparameter tuning, represents an innovative approach to mathematical discovery, suggesting potential applications to other combinatorial geometry problems."}}
{"id": "2602.17110", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17110", "abs": "https://arxiv.org/abs/2602.17110", "authors": ["Tanisha Parulekar", "Ge Shi", "Josh Pinskier", "David Howard", "Jen Jen Chung"], "title": "Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching", "comment": null, "summary": "A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.", "AI": {"tldr": "A CFM-based framework maps rigid gripper grasp poses to soft Fin-ray gripper poses, achieving significantly higher success rates than rigid pose baselines.", "motivation": "Existing grasp synthesis methods (like Anygrasp) are designed for rigid parallel grippers and fail to capture the unique compliant behaviors of soft grippers, leading to data-intensive and inaccurate models for soft robotic grasping.", "method": "Proposes a framework using Conditional Flow Matching (CFM) to map grasp poses from rigid to soft Fin-ray grippers. Includes a data collection pipeline for paired rigid-soft grasp poses, and uses a U-Net autoencoder to condition CFM on object geometry from depth images, learning continuous mapping from initial Anygrasp poses to stable soft gripper poses.", "result": "CFM-generated poses achieve 34% success rate for seen objects and 46% for unseen objects with soft gripper, significantly outperforming baseline rigid poses (6% and 25% respectively). Particularly effective for cylindrical (50%/100% success) and spherical objects (25%/31% success), demonstrating successful generalization to unseen objects.", "conclusion": "CFM provides a data-efficient and effective method for transferring grasp strategies from rigid to soft grippers, offering a scalable methodology applicable to other soft robotic systems."}}
{"id": "2602.16812", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16812", "abs": "https://arxiv.org/abs/2602.16812", "authors": ["Zhongcan Xiao", "Leyi Zhang", "Guannan Zhang", "Xiaoping Wang"], "title": "NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography", "comment": null, "summary": "Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis efficiency, NeuDiff Agent is introduced as a governed, tool-using AI workflow for TOPAZ at the Spallation Neutron Source that takes instrument data products through reduction, integration, refinement, and validation to a validated crystal structure and a publication-ready CIF. NeuDiff Agent executes this established pipeline under explicit governance by restricting actions to allowlisted tools, enforcing fail-closed verification gates at key workflow boundaries, and capturing complete provenance for inspection, auditing, and controlled replay. Performance is assessed using a fixed prompt protocol and repeated end-to-end runs with two large language model backends, with user and machine time partitioned and intervention burden and recovery behaviors quantified under gating. In a reference-case benchmark, NeuDiff Agent reduces wall time from 435 minutes (manual) to 86.5(4.7) to 94.4(3.5) minutes (4.6-5.0x faster) while producing a validated CIF with no checkCIF level A or B alerts. These results establish a practical route to deploy agentic AI in facility crystallography while preserving traceability and publication-facing validation requirements.", "AI": {"tldr": "NeuDiff Agent is a governed AI workflow that automates neutron diffraction data analysis from raw data to validated crystal structure, reducing analysis time by 4.6-5.0x while maintaining validation standards.", "motivation": "Large-scale neutron facilities face analysis latency as the bottleneck for scientific throughput, especially for complex samples requiring iterative reduction, integration, refinement, and validation steps. Manual processes are time-consuming and inefficient.", "method": "NeuDiff Agent is a governed, tool-using AI workflow that executes the established crystallography pipeline (reduction, integration, refinement, validation) under explicit governance. It restricts actions to allowlisted tools, enforces fail-closed verification gates at workflow boundaries, and captures complete provenance for inspection and auditing.", "result": "In benchmark testing, NeuDiff Agent reduced wall time from 435 minutes (manual) to 86.5-94.4 minutes (4.6-5.0x faster) while producing validated CIF files with no checkCIF level A or B alerts. The system demonstrated reliable performance across different LLM backends with quantified intervention burden and recovery behaviors.", "conclusion": "NeuDiff Agent establishes a practical route to deploy agentic AI in facility crystallography while preserving traceability and publication-facing validation requirements, significantly improving analysis efficiency and time-to-result for complex neutron diffraction data."}}
{"id": "2602.17128", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17128", "abs": "https://arxiv.org/abs/2602.17128", "authors": ["Huishi Huang", "Jack Klusmann", "Haozhe Wang", "Shuchen Ji", "Fengkang Ying", "Yiyuan Zhang", "John Nassour", "Gordon Cheng", "Daniela Rus", "Jun Liu", "Marcelo H Ang", "Cecilia Laschi"], "title": "Physical Human-Robot Interaction for Grasping in Augmented Reality via Rigid-Soft Robot Synergy", "comment": "Camera-ready version for RoboSoft 2026. 8 pages, 6 figures", "summary": "Hybrid rigid-soft robots combine the precision of rigid manipulators with the compliance and adaptability of soft arms, offering a promising approach for versatile grasping in unstructured environments. However, coordinating hybrid robots remains challenging, due to difficulties in modeling, perception, and cross-domain kinematics. In this work, we present a novel augmented reality (AR)-based physical human-robot interaction framework that enables direct teleoperation of a hybrid rigid-soft robot for simple reaching and grasping tasks. Using an AR headset, users can interact with a simulated model of the robotic system integrated into a general-purpose physics engine, which is superimposed on the real system, allowing simulated execution prior to real-world deployment. To ensure consistent behavior between the virtual and physical robots, we introduce a real-to-simulation parameter identification pipeline that leverages the inherent geometric properties of the soft robot, enabling accurate modeling of its static and dynamic behavior as well as the control system's response.", "AI": {"tldr": "AR-based teleoperation framework for hybrid rigid-soft robots using simulated execution with real-to-simulation parameter identification for consistent virtual-physical behavior", "motivation": "Hybrid rigid-soft robots offer precision and compliance for unstructured environments, but coordination remains challenging due to modeling, perception, and cross-domain kinematics difficulties", "method": "AR-based physical human-robot interaction framework using AR headset to interact with simulated robot model in physics engine, with real-to-simulation parameter identification pipeline leveraging soft robot's geometric properties", "result": "Framework enables direct teleoperation of hybrid rigid-soft robot for simple reaching and grasping tasks with consistent behavior between virtual and physical systems", "conclusion": "AR-based teleoperation with parameter identification addresses coordination challenges in hybrid rigid-soft robots, enabling effective human-robot interaction for grasping tasks"}}
{"id": "2602.16814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16814", "abs": "https://arxiv.org/abs/2602.16814", "authors": ["Eiman Kanjo", "Mustafa Aslanov"], "title": "Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI", "comment": "16 pages, 3 figures, 3 tables, this paper introduces a new concept", "summary": "The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. In this paper, we introduce Node Learning, a decen- tralised learning paradigm in which intelligence resides at individual edge nodes and expands through selective peer interaction. Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchro- nisation or central aggregation. It unifies autonomous and cooperative behaviour within a single abstraction and accommodates heterogeneity in data, hardware, objectives, and connectivity. This concept paper develops the conceptual foundations of this paradigm, contrasts it with existing decentralised approaches, and examines implications for communi- cation, hardware, trust, and governance. Node Learning does not discard existing paradigms, but places them within a broader decentralised perspective", "AI": {"tldr": "Node Learning is a decentralized AI paradigm where intelligence resides at individual edge nodes and expands through selective peer interactions, enabling continuous local learning and opportunistic knowledge exchange without central coordination.", "motivation": "The paper addresses limitations of centralized AI at the edge: high data transmission costs, latency, energy consumption, and dependence on large data centers that scale poorly across heterogeneous, mobile, and resource-constrained environments.", "method": "Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchronization or central aggregation.", "result": "The paper develops conceptual foundations for Node Learning, contrasts it with existing decentralized approaches, and examines implications for communication, hardware, trust, and governance in edge AI systems.", "conclusion": "Node Learning provides a unified abstraction for autonomous and cooperative behavior that accommodates heterogeneity in data, hardware, objectives, and connectivity, placing existing paradigms within a broader decentralized perspective without discarding them."}}
{"id": "2602.17166", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17166", "abs": "https://arxiv.org/abs/2602.17166", "authors": ["Antonio Franchi", "Chiara Gabellieri"], "title": "Geometric Inverse Flight Dynamics on SO(3) and Application to Tethered Fixed-Wing Aircraft", "comment": null, "summary": "We present a robotics-oriented, coordinate-free formulation of inverse flight dynamics for fixed-wing aircraft on SO(3). Translational force balance is written in the world frame and rotational dynamics in the body frame; aerodynamic directions (drag, lift, side) are defined geometrically, avoiding local attitude coordinates. Enforcing coordinated flight (no sideslip), we derive a closed-form trajectory-to-input map yielding the attitude, angular velocity, and thrust-angle-of-attack pair, and we recover the aerodynamic moment coefficients component-wise. Applying such a map to tethered flight on spherical parallels, we obtain analytic expressions for the required bank angle and identify a specific zero-bank locus where the tether tension exactly balances centrifugal effects, highlighting the decoupling between aerodynamic coordination and the apparent gravity vector. Under a simple lift/drag law, the minimal-thrust angle of attack admits a closed form. These pointwise quasi-steady inversion solutions become steady-flight trim when the trajectory and rotational dynamics are time-invariant. The framework bridges inverse simulation in aeronautics with geometric modeling in robotics, providing a rigorous building block for trajectory design and feasibility checks.", "AI": {"tldr": "Coordinate-free inverse flight dynamics formulation on SO(3) for fixed-wing aircraft, enabling closed-form trajectory-to-input mapping with applications to tethered flight analysis.", "motivation": "Bridge inverse simulation in aeronautics with geometric modeling in robotics by developing a coordinate-free formulation that avoids local attitude coordinates and provides rigorous building blocks for trajectory design and feasibility checks.", "method": "Coordinate-free formulation on SO(3) with translational force balance in world frame and rotational dynamics in body frame; geometric definition of aerodynamic directions; enforcement of coordinated flight (no sideslip) to derive closed-form trajectory-to-input map yielding attitude, angular velocity, and thrust-angle-of-attack pair.", "result": "Derived analytic expressions for required bank angle in tethered flight on spherical parallels, identified zero-bank locus where tether tension balances centrifugal effects, obtained closed-form minimal-thrust angle of attack under simple lift/drag law, and established that pointwise quasi-steady inversion solutions become steady-flight trim when trajectory and rotational dynamics are time-invariant.", "conclusion": "The framework successfully bridges aeronautical inverse simulation with robotic geometric modeling, providing a rigorous mathematical foundation for trajectory design and feasibility analysis in fixed-wing aircraft control."}}
{"id": "2602.16827", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16827", "abs": "https://arxiv.org/abs/2602.16827", "authors": ["Luis Merino", "Gabriel Navarro", "Carlos Salvatierra", "Evangelina Santos"], "title": "An order-oriented approach to scoring hesitant fuzzy elements", "comment": null, "summary": "Traditional scoring approaches on hesitant fuzzy sets often lack a formal base in order theory. This paper proposes a unified framework, where each score is explicitly defined with respect to a given order. This order-oriented perspective enables more flexible and coherent scoring mechanisms. We examine several classical orders on hesitant fuzzy elements, that is, nonempty subsets in [0,1], and show that, contrary to prior claims, they do not induce lattice structures. In contrast, we prove that the scores defined with respect to the symmetric order satisfy key normative criteria for scoring functions, including strong monotonicity with respect to unions and the G\u00e4rdenfors condition.\n  Following this analysis, we introduce a class of functions, called dominance functions, for ranking hesitant fuzzy elements. They aim to compare hesitant fuzzy elements relative to control sets incorporating minimum acceptability thresholds. Two concrete examples of dominance functions for finite sets are provided: the discrete dominance function and the relative dominance function. We show that these can be employed to construct fuzzy preference relations on typical hesitant fuzzy sets and support group decision-making.", "AI": {"tldr": "The paper proposes an order-oriented scoring framework for hesitant fuzzy sets, shows classical orders don't form lattices, introduces dominance functions for ranking, and demonstrates applications in group decision-making.", "motivation": "Traditional scoring approaches for hesitant fuzzy sets lack formal order-theoretic foundations, leading to inconsistent and inflexible ranking mechanisms that don't properly account for underlying mathematical structures.", "method": "1) Develops a unified framework where scores are explicitly defined relative to given orders; 2) Analyzes classical orders on hesitant fuzzy elements; 3) Proves symmetric order satisfies normative scoring criteria; 4) Introduces dominance functions for ranking relative to control sets with minimum thresholds; 5) Provides concrete examples: discrete and relative dominance functions for finite sets.", "result": "1) Classical orders on hesitant fuzzy elements do not induce lattice structures (contrary to prior claims); 2) Scores defined with respect to symmetric order satisfy key normative criteria including strong monotonicity with respect to unions and the G\u00e4rdenfors condition; 3) Dominance functions enable construction of fuzzy preference relations and support group decision-making.", "conclusion": "The order-oriented framework provides mathematically rigorous scoring mechanisms for hesitant fuzzy sets, with dominance functions offering practical tools for ranking and decision-making applications while maintaining formal consistency with underlying order structures."}}
{"id": "2602.17199", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17199", "abs": "https://arxiv.org/abs/2602.17199", "authors": ["Antonio Rapuano", "Yaolei Shen", "Federico Califano", "Chiara Gabellieri", "Antonio Franchi"], "title": "Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place", "comment": "Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.", "AI": {"tldr": "A framework combining PDE-based cable modeling with reduced-order representation for real-time UAV cable manipulation control.", "motivation": "To enable real-time, dynamics-aware control of UAVs carrying suspended flexible cables, which requires handling complex cable oscillations and hybrid transitions while maintaining computational efficiency.", "method": "Develops a high-fidelity PDE model of extensible cable dynamics, discretizes it using finite-difference method, extracts reduced-order model via proper orthogonal decomposition, and implements nonlinear model predictive control for stabilization and hybrid transition handling.", "result": "Simulations confirm ROM stability, efficiency, and robustness; controller effectively regulates cable dynamics under various conditions; ROM enables trajectory planning in constrained environments.", "conclusion": "The framework successfully enables real-time, dynamics-aware control of UAVs with suspended flexible cables through combined high-fidelity modeling and reduced-order representation for practical implementation."}}
{"id": "2602.17226", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17226", "abs": "https://arxiv.org/abs/2602.17226", "authors": ["Lorenzo Montano-Olivan", "Julio A. Placed", "Luis Montano", "Maria T. Lazaro"], "title": "Multi-session Localization and Mapping Exploiting Topological Information", "comment": null, "summary": "Operating in previously visited environments is becoming increasingly crucial for autonomous systems, with direct applications in autonomous driving, surveying, and warehouse or household robotics. This repeated exposure to observing the same areas poses significant challenges for mapping and localization -- key components for enabling any higher-level task. In this work, we propose a novel multi-session framework that builds on map-based localization, in contrast to the common practice of greedily running full SLAM sessions and trying to find correspondences between the resulting maps. Our approach incorporates a topology-informed, uncertainty-aware decision-making mechanism that analyzes the pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. The resulting map and pose-graph are seamlessly integrated into the existing model, reducing accumulated error and enhancing global consistency. We validate our method on overlapping sequences from datasets and demonstrate its effectiveness in a real-world mine-like environment.", "AI": {"tldr": "A multi-session framework for autonomous systems that uses map-based localization with topology-informed decision-making to selectively trigger mapping and loop closing in low-connectivity regions, improving global consistency.", "motivation": "Operating in previously visited environments is crucial for autonomous systems (driving, surveying, robotics), but repeated exposure to the same areas poses significant challenges for mapping and localization, which are key for higher-level tasks.", "method": "Proposes a novel multi-session framework based on map-based localization (contrary to greedy full SLAM sessions). Incorporates topology-informed, uncertainty-aware decision-making that analyzes pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. Results are seamlessly integrated into existing model.", "result": "Validated on overlapping sequences from datasets and demonstrated effectiveness in a real-world mine-like environment. The approach reduces accumulated error and enhances global consistency.", "conclusion": "The proposed multi-session framework with topology-informed decision-making effectively addresses challenges of repeated environment exposure, improving mapping and localization for autonomous systems operating in previously visited areas."}}
{"id": "2602.16855", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16855", "abs": "https://arxiv.org/abs/2602.16855", "authors": ["Haiyang Xu", "Xi Zhang", "Haowei Liu", "Junyang Wang", "Zhaozai Zhu", "Shengjie Zhou", "Xuhao Hu", "Feiyu Gao", "Junjie Cao", "Zihua Wang", "Zhiyuan Chen", "Jitong Liao", "Qi Zheng", "Jiahui Zeng", "Ze Xu", "Shuai Bai", "Junyang Lin", "Jingren Zhou", "Ming Yan"], "title": "Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents", "comment": "25 pages, 11 figures, 11 tables", "summary": "The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding tasks, it obtains 80.3 on ScreenSpotPro; (3) on tool-calling tasks, it obtains 47.6 on OSWorld-MCP, and 46.8 on MobileWorld; (4) on memory and knowledge tasks, it obtains 75.5 on GUI-Knowledge Bench. GUI-Owl-1.5 incorporates several key innovations: (1) Hybird Data Flywheel: we construct the data pipeline for UI understanding and trajectory generation based on a combination of simulated environments and cloud-based sandbox environments, in order to improve the efficiency and quality of data collection. (2) Unified Enhancement of Agent Capabilities: we use a unified thought-synthesis pipeline to enhance the model's reasoning capabilities, while placing particular emphasis on improving key agent abilities, including Tool/MCP use, memory and multi-agent adaptation; (3) Multi-platform Environment RL Scaling: We propose a new environment RL algorithm, MRPO, to address the challenges of multi-platform conflicts and the low training efficiency of long-horizon tasks. The GUI-Owl-1.5 models are open-sourced, and an online cloud-sandbox demo is available at https://github.com/X-PLUG/MobileAgent.", "code_url": "https://github.com/X-PLUG/MobileAgen", "AI": {"tldr": "GUI-Owl-1.5 is a state-of-the-art native GUI agent model with multiple size variants (2B-235B) that achieves SOTA performance across 20+ GUI benchmarks for automation, grounding, tool-calling, and knowledge tasks, featuring hybrid data collection, unified capability enhancement, and multi-platform RL scaling.", "motivation": "To develop a comprehensive GUI agent model that can handle diverse GUI automation tasks across multiple platforms (desktop, mobile, browser) with cloud-edge collaboration capabilities, addressing challenges in data collection efficiency, multi-platform conflicts, and long-horizon task training.", "method": "Three key innovations: (1) Hybrid Data Flywheel combining simulated and cloud-based sandbox environments for UI understanding and trajectory generation; (2) Unified thought-synthesis pipeline to enhance reasoning capabilities with focus on tool/MCP use, memory, and multi-agent adaptation; (3) Multi-platform Environment RL Scaling using MRPO algorithm to address platform conflicts and improve training efficiency for long-horizon tasks.", "result": "Achieves state-of-the-art results on 20+ GUI benchmarks: 56.5 on OSWorld, 71.6 on AndroidWorld, 48.4 on WebArena for automation; 80.3 on ScreenSpotPro for grounding; 47.6 on OSWorld-MCP and 46.8 on MobileWorld for tool-calling; 75.5 on GUI-Knowledge Bench for memory/knowledge tasks.", "conclusion": "GUI-Owl-1.5 represents a significant advancement in GUI agent technology with comprehensive multi-platform support, superior benchmark performance, and innovative approaches to data collection, capability enhancement, and RL scaling, with open-source availability and cloud-sandbox demonstration."}}
{"id": "2602.17259", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17259", "abs": "https://arxiv.org/abs/2602.17259", "authors": ["Han Zhao", "Jingbo Wang", "Wenxuan Song", "Shuai Chen", "Yang Liu", "Yan Wang", "Haoang Li", "Donglin Wang"], "title": "FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment", "comment": "Project Website: https://h-zhao1997.github.io/frappe", "summary": "Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.", "AI": {"tldr": "FRAPPE is a two-stage fine-tuning method that improves world modeling in VLA models by predicting future latent representations instead of pixel-level reconstructions, reducing error accumulation and enhancing generalization for robotic policies.", "motivation": "Current world modeling approaches for VLA models have two main issues: 1) training objectives force over-emphasis on pixel-level reconstruction, constraining semantic learning and generalization, and 2) reliance on predicted future observations during inference leads to error accumulation. These limitations hinder the development of effective world-aware robotic policies.", "method": "FRAPPE (Future Representation Alignment via Parallel Progressive Expansion) uses a two-stage fine-tuning strategy: 1) Mid-training phase: the model learns to predict latent representations of future observations rather than pixel-level reconstructions; 2) Post-training phase: computational workload is expanded in parallel while simultaneously aligning representations with multiple different visual foundation models. This approach improves fine-tuning efficiency and reduces dependence on action-annotated data.", "result": "Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios. The method provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies.", "conclusion": "FRAPPE addresses key limitations in current world modeling approaches by shifting from pixel-level reconstruction to latent representation prediction, reducing error accumulation, and enabling more efficient fine-tuning. This represents a significant advancement toward developing robust, world-aware robotic policies with improved generalization capabilities."}}
{"id": "2602.16891", "categories": ["cs.AI", "cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16891", "abs": "https://arxiv.org/abs/2602.16891", "authors": ["Hongwei Li", "Zhun Wang", "Qinrun Dai", "Yuzhou Nie", "Jinjun Peng", "Ruitong Liu", "Jingyang Zhang", "Kaijie Zhu", "Jingxuan He", "Lun Wang", "Yangruibo Ding", "Yueqi Chen", "Wenbo Guo", "Dawn Song"], "title": "OpenSage: Self-programming Agent Generation Engine", "comment": null, "summary": "Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or rely on humans to manually design these components, limiting agents' generalizability and overall performance. We propose OpenSage, the first ADK that enables LLMs to automatically create agents with self-generated topology and toolsets while providing comprehensive and structured memory support. OpenSage offers effective functionality for agents to create and manage their own sub-agents and toolkits. It also features a hierarchical, graph-based memory system for efficient management and a specialized toolkit tailored to software engineering tasks. Extensive experiments across three state-of-the-art benchmarks with various backbone models demonstrate the advantages of OpenSage over existing ADKs. We also conduct rigorous ablation studies to demonstrate the effectiveness of our design for each component. We believe OpenSage can pave the way for the next generation of agent development, shifting the focus from human-centered to AI-centered paradigms.", "AI": {"tldr": "OpenSage is the first agent development kit that enables LLMs to automatically create agents with self-generated topology and toolsets, featuring hierarchical graph-based memory and specialized software engineering toolkits, outperforming existing ADKs across multiple benchmarks.", "motivation": "Current agent development kits either lack sufficient functional support or require manual human design of agent topology, tools, and memory components, which limits agents' generalizability and overall performance.", "method": "OpenSage enables LLMs to automatically create agents with self-generated topology and toolsets, provides comprehensive structured memory support with a hierarchical graph-based memory system, and includes specialized toolkits for software engineering tasks.", "result": "Extensive experiments across three state-of-the-art benchmarks with various backbone models demonstrate OpenSage's advantages over existing ADKs, with rigorous ablation studies confirming the effectiveness of each design component.", "conclusion": "OpenSage represents a paradigm shift from human-centered to AI-centered agent development, paving the way for next-generation agent systems by enabling automatic agent creation with self-generated components."}}
{"id": "2602.17393", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.17393", "abs": "https://arxiv.org/abs/2602.17393", "authors": ["Minxing Sun", "Yao Mao"], "title": "Contact-Anchored Proprioceptive Odometry for Quadruped Robots", "comment": "28 pages, 30 figures", "summary": "Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\\sim$200\\,m horizontal loop and a $\\sim$15\\,m vertical loop return with 0.1638\\,m and 0.219\\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\\,m and 0.199\\,m. On wheel-legged robot~C, a $\\sim$700\\,m horizontal loop yields 7.68\\,m error and a $\\sim$20\\,m vertical loop yields 0.540\\,m error. Unitree Go2 EDU closes a $\\sim$120\\,m horizontal loop with 2.2138\\,m error and a $\\sim$8\\,m vertical loop with less than 0.1\\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git", "AI": {"tldr": "A proprioceptive state estimator using only IMU and motor measurements to estimate body pose and velocity for legged robots, leveraging contact-based kinematic constraints and novel drift correction techniques.", "motivation": "Reliable odometry for legged robots without cameras or LiDAR is challenging due to IMU drift and noisy joint velocity sensing, creating a need for purely proprioceptive solutions.", "method": "Treats contacting legs as kinematic anchors using joint-torque-based foot wrench estimation for contact selection; introduces height clustering with time-decay correction for elevation drift; applies inverse-kinematics cubature Kalman filter for foot velocity estimation; uses multi-contact geometric consistency for yaw drift mitigation.", "result": "Evaluated on four quadruped platforms with closed-loop trajectories: Astrall point-foot robot achieved 0.1638m error on ~200m horizontal loop and 0.219m error on ~15m vertical loop; wheel-legged robots showed similar performance with errors ranging from 0.199m to 7.68m depending on distance.", "conclusion": "The method provides effective drift suppression for legged robot odometry using only proprioceptive sensors, with unified formulation applicable to various robot types and graceful degradation when IMU constraints are unreliable."}}
{"id": "2602.16901", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16901", "abs": "https://arxiv.org/abs/2602.16901", "authors": ["Tanqiu Jiang", "Yuhui Wang", "Jiacheng Liang", "Ting Wang"], "title": "AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks", "comment": null, "summary": "LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack types including intent hijacking, tool chaining, task injection, objective drifting, and memory poisoning, spanning 28 realistic agentic environments, and 644 security test cases. Leveraging AgentLAB, we evaluate representative LLM agents and find that they remain highly susceptible to long-horizon attacks; moreover, defenses designed for single-turn interactions fail to reliably mitigate long-horizon threats. We anticipate that AgentLAB will serve as a valuable benchmark for tracking progress on securing LLM agents in practical settings. The benchmark is publicly available at https://tanqiujiang.github.io/AgentLAB_main.", "code_url": "https://tanqiujiang.github.io/AgentLAB_main", "AI": {"tldr": "AgentLAB is the first benchmark for evaluating LLM agent vulnerabilities to adaptive, long-horizon attacks across 28 environments and 644 test cases, revealing current agents remain highly susceptible despite single-turn defenses.", "motivation": "As LLM agents are increasingly deployed in complex, long-horizon environments, they become exposed to sophisticated multi-turn attacks that exploit user-agent-environment interactions, creating security risks that cannot be addressed by single-turn defenses.", "method": "Developed AgentLAB benchmark with five novel attack types (intent hijacking, tool chaining, task injection, objective drifting, memory poisoning) across 28 realistic agentic environments and 644 security test cases to systematically evaluate agent vulnerabilities.", "result": "Evaluation of representative LLM agents shows they remain highly susceptible to long-horizon attacks, and existing defenses designed for single-turn interactions fail to reliably mitigate these multi-turn threats.", "conclusion": "AgentLAB serves as a valuable benchmark for tracking progress on securing LLM agents in practical settings, highlighting the need for new defense mechanisms specifically designed for long-horizon threats."}}
{"id": "2602.17415", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17415", "abs": "https://arxiv.org/abs/2602.17415", "authors": ["Yi Zhang", "Omar Faris", "Chapa Sirithunge", "Kai-Fung Chu", "Fumiya Iida", "Fulvio Forni"], "title": "Distributed Virtual Model Control for Scalable Human-Robot Collaboration in Shared Workspace", "comment": null, "summary": "We present a decentralized, agent agnostic, and safety-aware control framework for human-robot collaboration based on Virtual Model Control (VMC). In our approach, both humans and robots are embedded in the same virtual-component-shaped workspace, where motion is the result of the interaction with virtual springs and dampers rather than explicit trajectory planning. A decentralized, force-based stall detector identifies deadlocks, which are resolved through negotiation. This reduces the probability of robots getting stuck in the block placement task from up to 61.2% to zero in our experiments. The framework scales without structural changes thanks to the distributed implementation: in experiments we demonstrate safe collaboration with up to two robots and two humans, and in simulation up to four robots, maintaining inter-agent separation at around 20 cm. Results show that the method shapes robot behavior intuitively by adjusting control parameters and achieves deadlock-free operation across team sizes in all tested scenarios.", "AI": {"tldr": "Decentralized VMC framework enables safe human-robot collaboration using virtual springs/dampers instead of trajectory planning, with stall detection and negotiation to eliminate deadlocks.", "motivation": "Need for safe, scalable human-robot collaboration systems that avoid deadlocks and maintain safety without requiring explicit trajectory planning or centralized control.", "method": "Virtual Model Control with virtual springs/dampers in shared workspace, decentralized force-based stall detection, and negotiation for deadlock resolution in distributed implementation.", "result": "Reduced deadlock probability from 61.2% to zero in block placement tasks, maintained ~20cm inter-agent separation with up to 4 robots in simulation, and achieved deadlock-free operation across all tested team sizes.", "conclusion": "The decentralized VMC framework provides intuitive, safe, and scalable human-robot collaboration with effective deadlock resolution through virtual component interaction and negotiation."}}
{"id": "2602.16902", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16902", "abs": "https://arxiv.org/abs/2602.16902", "authors": ["Juliusz Ziomek", "William Bankes", "Lorenz Wolf", "Shyam Sundhar Ramesh", "Xiaohang Tang", "Ilija Bogunovic"], "title": "LLM-WikiRace: Benchmarking Long-term Planning and Reasoning over Real-World Knowledge Graphs", "comment": null, "summary": "We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability to reason about how concepts are connected in the real world. We evaluate a broad set of open- and closed-source models, including Gemini-3, GPT-5, and Claude Opus 4.5, which achieve the strongest results on the easy level of the task and demonstrate superhuman performance. Despite this, performance drops sharply on hard difficulty: the best-performing model, Gemini-3, succeeds in only 23\\% of hard games, highlighting substantial remaining challenges for frontier models. Our analysis shows that world knowledge is a necessary ingredient for success, but only up to a point, beyond this threshold, planning and long-horizon reasoning capabilities become the dominant factors. Trajectory-level analysis further reveals that even the strongest models struggle to replan after failure, frequently entering loops rather than recovering. LLM-Wikirace is a simple benchmark that reveals clear limitations in current reasoning systems, offering an open arena where planning-capable LLMs still have much to prove. Our code and leaderboard available at https:/llmwikirace.github.io.", "AI": {"tldr": "LLM-Wikirace is a benchmark evaluating LLMs' planning, reasoning, and world knowledge through Wikipedia navigation tasks, revealing that while frontier models achieve superhuman performance on easy levels, they struggle significantly on hard difficulties, with planning and long-horizon reasoning emerging as key limitations.", "motivation": "To create a benchmark that evaluates planning, reasoning, and world knowledge in LLMs through the concrete task of Wikipedia navigation, which requires step-by-step hyperlink traversal with look-ahead planning and understanding of real-world concept connections.", "method": "Developed LLM-Wikirace benchmark where models must navigate from a source Wikipedia page to a target page using hyperlinks, evaluating both open- and closed-source models (including Gemini-3, GPT-5, Claude Opus 4.5) across easy and hard difficulty levels, with trajectory-level analysis of planning behavior.", "result": "Frontier models achieve superhuman performance on easy tasks but performance drops sharply on hard difficulty (best model Gemini-3 succeeds in only 23% of hard games). World knowledge is necessary but insufficient beyond a threshold, where planning and long-horizon reasoning become dominant factors. Models struggle with replanning after failure and frequently enter loops.", "conclusion": "LLM-Wikirace reveals clear limitations in current reasoning systems, showing that planning-capable LLMs still have substantial challenges in long-horizon reasoning and recovery from failures, providing an open arena for future improvement in planning and reasoning capabilities."}}
{"id": "2602.17421", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17421", "abs": "https://arxiv.org/abs/2602.17421", "authors": ["Diana Cafiso", "Petr Trunin", "Carolina Gay", "Lucia Beccai"], "title": "3D-printed Soft Optical sensor with a Lens (SOLen) for light guidance in mechanosensing", "comment": "11 pages, 5 figures, submitted to Materials & Design", "summary": "Additive manufacturing is enabling soft robots with increasingly complex geometries, creating a demand for sensing solutions that remain compatible with single-material, one-step fabrication. Optical soft sensors are attractive for monolithic printing, but their performance is often degraded by uncontrolled light propagation (ambient coupling, leakage, scattering), while common miti- gation strategies typically require multimaterial interfaces. Here, we present an approach for 3D printed soft optical sensing (SOLen), in which a printed lens is placed in front of an emitter within a Y-shaped waveguide. The sensing mechanism relies on deformation-induced lens rotation and focal-spot translation, redistributing optical power between the two branches to generate a differential output that encodes both motion direction and amplitude. An acrylate polyurethane resin was modified with lauryl acrylate to improve compliance and optical transmittance, and single-layer optical characterization was used to derive wavelength-dependent refractive index and transmittance while minimizing DLP layer-related artifacts. The measured refractive index was used in simulations to design a lens profile for a target focal distance, which was then printed with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. These results establish a transferable material-to-optics workflow for soft optical sensors with lens with new functionalities for next-generation soft robots", "AI": {"tldr": "SOLen is a 3D printed soft optical sensing approach using a printed lens within a Y-shaped waveguide to detect deformation through lens rotation and focal-spot translation, enabling direction and amplitude sensing in single-material fabrication.", "motivation": "Additive manufacturing enables complex soft robot geometries, creating demand for sensing solutions compatible with single-material, one-step fabrication. Optical soft sensors are attractive but suffer from uncontrolled light propagation issues, while mitigation strategies typically require multimaterial interfaces.", "method": "Developed SOLen approach with printed lens placed in front of an emitter within Y-shaped waveguide. Modified acrylate polyurethane resin with lauryl acrylate for improved compliance and optical transmittance. Used single-layer optical characterization to derive wavelength-dependent refractive index and transmittance. Simulated lens profile using measured refractive index for target focal distance, then printed with sub-millimeter fidelity.", "result": "Successfully printed lens with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. The differential output encodes both motion direction and amplitude through deformation-induced lens rotation and focal-spot translation.", "conclusion": "Established a transferable material-to-optics workflow for soft optical sensors with lenses, enabling new functionalities for next-generation soft robots through single-material, one-step fabrication compatible sensing solutions."}}
{"id": "2602.16931", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16931", "abs": "https://arxiv.org/abs/2602.16931", "authors": ["Idhant Gulati", "Shivam Raval"], "title": "Narrow fine-tuning erodes safety alignment in vision-language agents", "comment": "24 pages, 11 figures", "summary": "Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimodal evaluation reveals substantially higher misalignment ($70.71 \\pm 1.22$ at $r=128$) than text-only evaluation ($41.19 \\pm 2.51$), suggesting that unimodal safety benchmarks may underestimate alignment degradation in vision-language models. Critically, even 10\\% harmful data in the training mixture induces substantial alignment degradation. Geometric analysis reveals that harmful behaviors occupy a remarkably low-dimensional subspace, with the majority of misalignment information captured in 10 principal components. To mitigate misalignment, we evaluate two strategies: benign narrow fine-tuning and activation-based steering. While both approaches substantially reduce misalignment, neither completely removes the learned harmful behaviors. Our findings highlight the need for robust continual learning frameworks, as current post-training paradigms may not sufficiently preserve alignment in post-deployment settings.", "AI": {"tldr": "Fine-tuning aligned vision-language models on harmful datasets causes severe emergent misalignment that generalizes broadly, with multimodal evaluation revealing worse degradation than text-only benchmarks suggest.", "motivation": "Lifelong multimodal agents need continuous adaptation through post-training, but this creates tension between acquiring capabilities and preserving safety alignment. The paper investigates how fine-tuning aligned models on harmful data affects safety alignment.", "method": "Experiments on Gemma3-4B with LoRA fine-tuning on harmful datasets, evaluating misalignment across tasks and modalities. Geometric analysis using PCA to examine harmful behavior subspace. Evaluation of mitigation strategies: benign narrow fine-tuning and activation-based steering.", "result": "Fine-tuning induces severe emergent misalignment that generalizes broadly. Misalignment scales with LoRA rank, with multimodal evaluation showing 70.71\u00b11.22 (vs 41.19\u00b12.51 text-only). Even 10% harmful data causes substantial degradation. Harmful behaviors occupy low-dimensional subspace (10 principal components capture majority). Mitigation strategies reduce but don't completely remove harmful behaviors.", "conclusion": "Current post-training paradigms may not sufficiently preserve alignment in deployment settings. Need robust continual learning frameworks as unimodal safety benchmarks underestimate alignment degradation in vision-language models."}}
{"id": "2602.17472", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17472", "abs": "https://arxiv.org/abs/2602.17472", "authors": ["Mohamed Sabry", "Joseba Gorospe", "Cristina Olaverri-Monreal"], "title": "A Cost-Effective and Climate-Resilient Air Pressure System for Rain Effect Reduction on Automated Vehicle Cameras", "comment": null, "summary": "Recent advances in automated vehicles have focused on improving perception performance under adverse weather conditions; however, research on physical hardware solutions remains limited, despite their importance for perception critical applications such as vehicle platooning. Existing approaches, such as hydrophilic or hydrophobic lenses and sprays, provide only partial mitigation, while industrial protection systems imply high cost and they do not enable scalability for automotive deployment.\n  To address these limitations, this paper presents a cost-effective hardware solution for rainy conditions, designed to be compatible with multiple cameras simultaneously.\n  Beyond its technical contribution, the proposed solution supports sustainability goals in transportation systems. By enabling compatibility with existing camera-based sensing platforms, the system extends the operational reliability of automated vehicles without requiring additional high-cost sensors or hardware replacements. This approach reduces resource consumption, supports modular upgrades, and promotes more cost-efficient deployment of automated vehicle technologies, particularly in challenging weather conditions where system failures would otherwise lead to inefficiencies and increased emissions. The proposed system was able to increase pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6%.", "AI": {"tldr": "A cost-effective hardware solution for rainy conditions improves camera-based perception for automated vehicles, increasing pedestrian detection accuracy from 8.3% to 41.6% while supporting sustainability goals.", "motivation": "Current automated vehicle perception systems struggle in adverse weather, especially rain, with existing hardware solutions being either partially effective, expensive, or not scalable for automotive deployment. There's a need for affordable, scalable hardware that maintains perception reliability in challenging conditions.", "method": "The paper presents a cost-effective hardware solution designed for rainy conditions that is compatible with multiple cameras simultaneously. The system works with existing camera-based sensing platforms without requiring additional high-cost sensors or hardware replacements.", "result": "The proposed system significantly improved pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6% in rainy conditions. The solution extends operational reliability of automated vehicles while being cost-effective and scalable.", "conclusion": "This hardware solution addresses the gap in affordable, scalable rain mitigation for automated vehicle perception systems. Beyond technical improvements, it supports sustainability goals by reducing resource consumption, enabling modular upgrades, and promoting cost-efficient deployment of automated vehicle technologies in challenging weather conditions."}}
{"id": "2602.16935", "categories": ["cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16935", "abs": "https://arxiv.org/abs/2602.16935", "authors": ["Justin Albrethsen", "Yash Datta", "Kunal Kumar", "Sharath Rajasekar"], "title": "DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs", "comment": "18 Pages, 7 Tables, 1 Figure", "summary": "While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a \"Safety Gap\" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed malicious intent across turn boundaries to bypass stateless filters. We introduce DeepContext, a stateful monitoring framework designed to map the temporal trajectory of user intent. DeepContext discards the isolated evaluation model in favor of a Recurrent Neural Network (RNN) architecture that ingests a sequence of fine-tuned turn-level embeddings. By propagating a hidden state across the conversation, DeepContext captures the incremental accumulation of risk that stateless models overlook. Our evaluation demonstrates that DeepContext significantly outperforms existing baselines in multi-turn jailbreak detection, achieving a state-of-the-art F1 score of 0.84, which represents a substantial improvement over both hyperscaler cloud-provider guardrails and leading open-weight models such as Llama-Prompt-Guard-2 (0.67) and Granite-Guardian (0.67). Furthermore, DeepContext maintains a sub-20ms inference overhead on a T4 GPU, ensuring viability for real-time applications. These results suggest that modeling the sequential evolution of intent is a more effective and computationally efficient alternative to deploying massive, stateless models.", "AI": {"tldr": "DeepContext is a stateful RNN-based framework for multi-turn jailbreak detection that tracks temporal intent evolution, outperforming stateless models with 0.84 F1 score while maintaining real-time inference efficiency.", "motivation": "Current LLM safety guardrails are stateless and treat multi-turn dialogues as disconnected events, creating a \"Safety Gap\" where adversarial tactics like Crescendo and ActorAttack can slowly bleed malicious intent across turn boundaries to bypass stateless filters.", "method": "DeepContext uses a Recurrent Neural Network (RNN) architecture that ingests sequences of fine-tuned turn-level embeddings, propagating a hidden state across conversations to capture incremental risk accumulation that stateless models overlook.", "result": "DeepContext achieves state-of-the-art F1 score of 0.84 in multi-turn jailbreak detection, significantly outperforming hyperscaler cloud-provider guardrails and leading open-weight models like Llama-Prompt-Guard-2 (0.67) and Granite-Guardian (0.67), while maintaining sub-20ms inference overhead on T4 GPU.", "conclusion": "Modeling the sequential evolution of intent through stateful architectures is more effective and computationally efficient than deploying massive stateless models for multi-turn safety monitoring."}}
{"id": "2602.17474", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17474", "abs": "https://arxiv.org/abs/2602.17474", "authors": ["Carolina Gay", "Petr Trunin", "Diana Cafiso", "Yuejun Xu", "Majid Taghavi", "Lucia Beccai"], "title": "Optically Sensorized Electro-Ribbon Actuator (OS-ERA)", "comment": "6 pages, 5 figures, accepted for 9th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2026)", "summary": "Electro-Ribbon Actuators (ERAs) are lightweight flexural actuators that exhibit ultrahigh displacement and fast movement. However, their embedded sensing relies on capacitive sensors with limited precision, which hinders accurate control. We introduce OS-ERA, an optically sensorized ERA that yields reliable proprioceptive information, and we focus on the design and integration of a sensing solution without affecting actuation. To analyse the complex curvature of an ERA in motion, we design and embed two soft optical waveguide sensors. A classifier is trained to map the sensing signals in order to distinguish eight bending states. We validate our model on six held-out trials and compare it against signals' trajectories learned from training runs. Across all tests, the sensing output signals follow the training manifold, and the predicted sequence mirrors real performance and confirms repeatability. Despite deliberate train-test mismatches in actuation speed, the signal trajectories preserve their shape, and classification remains consistently accurate, demonstrating practical voltage- and speed-invariance. As a result, OS-ERA classifies bending states with high fidelity; it is fast and repeatable, solving a longstanding bottleneck of the ERA, enabling steps toward closed-loop control.", "AI": {"tldr": "OS-ERA introduces optical waveguide sensors into Electro-Ribbon Actuators to enable accurate proprioceptive sensing and bending state classification, overcoming limitations of capacitive sensors for closed-loop control.", "motivation": "Electro-Ribbon Actuators (ERAs) have ultrahigh displacement and fast movement but rely on capacitive sensors with limited precision, hindering accurate control. There's a need for reliable proprioceptive sensing without affecting actuation performance.", "method": "Design and embed two soft optical waveguide sensors into ERA to analyze complex curvature. Train a classifier to map sensing signals to distinguish eight bending states. Validate model on held-out trials and compare against training signal trajectories.", "result": "OS-ERA successfully classifies bending states with high fidelity. Sensing signals follow training manifold, predicted sequences mirror real performance, and classification remains accurate despite voltage- and speed-variations, demonstrating practical invariance.", "conclusion": "OS-ERA solves the longstanding sensing bottleneck of ERAs by providing reliable proprioceptive information through optical sensing, enabling steps toward closed-loop control while maintaining actuator performance."}}
{"id": "2602.16942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16942", "abs": "https://arxiv.org/abs/2602.16942", "authors": ["Hexi Jin", "Stephen Liu", "Yuheng Li", "Simran Malik", "Yiying Zhang"], "title": "SourceBench: Can AI Answers Reference Quality Web Sources?", "comment": null, "summary": "Large language models (LLMs) increasingly answer queries by citing web sources, but existing evaluations emphasize answer correctness rather than evidence quality. We introduce SourceBench, a benchmark for measuring the quality of cited web sources across 100 real-world queries spanning informational, factual, argumentative, social, and shopping intents. SourceBench uses an eight-metric framework covering content quality (content relevance, factual accuracy, objectivity) and page-level signals (e.g., freshness, authority/accountability, clarity), and includes a human-labeled dataset with a calibrated LLM-based evaluator that matches expert judgments closely. We evaluate eight LLMs, Google Search, and three AI search tools over 3996 cited sources using SourceBench and conduct further experiments to understand the evaluation results. Overall, our work reveals four key new insights that can guide future research in the direction of GenAI and web search.", "AI": {"tldr": "SourceBench is a benchmark for evaluating the quality of web sources cited by LLMs, covering 100 real-world queries across multiple intents, using an 8-metric framework and human-labeled data with LLM-based evaluation.", "motivation": "Existing evaluations of LLMs focus primarily on answer correctness while neglecting the quality of cited web sources, despite the increasing use of web citations by LLMs in answering queries.", "method": "Developed SourceBench with 100 real-world queries spanning informational, factual, argumentative, social, and shopping intents. Created an 8-metric framework covering content quality (relevance, accuracy, objectivity) and page-level signals (freshness, authority, clarity). Built a human-labeled dataset and calibrated LLM-based evaluator matching expert judgments. Evaluated 8 LLMs, Google Search, and 3 AI search tools across 3996 cited sources.", "result": "The benchmark includes a calibrated LLM-based evaluator that closely matches expert judgments. Evaluation of multiple systems revealed four key new insights about source citation quality that can guide future research in GenAI and web search.", "conclusion": "SourceBench provides a comprehensive framework for evaluating web source quality in LLM citations, revealing important insights about current systems and establishing a foundation for future research in generative AI and web search integration."}}
{"id": "2602.17502", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17502", "abs": "https://arxiv.org/abs/2602.17502", "authors": ["Kyle R. Embry", "Lorenzo Vianello", "Jim Lipsey", "Frank Ursetta", "Michael Stephens", "Zhi Wang", "Ann M. Simon", "Andrea J. Ikeda", "Suzanne B. Finucane", "Shawana Anarwala", "Levi J. Hargrove"], "title": "Proximal powered knee placement: a case study", "comment": "Submitted to IEEE RAS/EMBS 11th International Conference on Biomedical Robotics and Biomechatronics (BioRob 2026)", "summary": "Lower limb amputation affects millions worldwide, leading to impaired mobility, reduced walking speed, and limited participation in daily and social activities. Powered prosthetic knees can partially restore mobility by actively assisting knee joint torque, improving gait symmetry, sit-to-stand transitions, and walking speed. However, added mass from powered components may diminish these benefits, negatively affecting gait mechanics and increasing metabolic cost. Consequently, optimizing mass distribution, rather than simply minimizing total mass, may provide a more effective and practical solution. In this exploratory study, we evaluated the feasibility of above-knee powertrain placement for a powered prosthetic knee in a small cohort. Compared to below-knee placement, the above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%), with mixed effects on gait symmetry. Kinematic measures indicated similar knee range of motion and peak velocity across configurations. Additional testing on ramps and stairs confirmed the robustness of the control strategy across multiple locomotion tasks. These preliminary findings suggest that above-knee placement is functionally feasible and that careful mass distribution can preserve the benefits of powered assistance while mitigating adverse effects of added weight. Further studies are needed to confirm these trends and guide design and clinical recommendations.", "AI": {"tldr": "Above-knee placement of powered prosthetic knee powertrain shows functional feasibility with improved walking speed and cadence compared to below-knee placement, suggesting mass distribution optimization can preserve powered assistance benefits.", "motivation": "Powered prosthetic knees improve mobility but added mass from powered components can diminish benefits by negatively affecting gait mechanics and metabolic cost. Optimizing mass distribution rather than minimizing total mass may provide more effective solutions.", "method": "Exploratory study evaluating feasibility of above-knee powertrain placement for powered prosthetic knee in small cohort. Compared above-knee vs below-knee configurations, measuring walking speed, cadence, gait symmetry, knee range of motion, and peak velocity. Additional testing on ramps and stairs to assess control strategy robustness across locomotion tasks.", "result": "Above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%) compared to below-knee placement, with mixed effects on gait symmetry. Kinematic measures showed similar knee range of motion and peak velocity across configurations. Control strategy remained robust across multiple locomotion tasks including ramps and stairs.", "conclusion": "Above-knee placement is functionally feasible for powered prosthetic knees. Careful mass distribution can preserve benefits of powered assistance while mitigating adverse effects of added weight. Further studies needed to confirm trends and guide design/clinical recommendations."}}
{"id": "2602.16943", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16943", "abs": "https://arxiv.org/abs/2602.16943", "authors": ["Arnold Cartagena", "Ariane Teixeira"], "title": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents", "comment": "23 pages, 5 figures, 4 tables, code and data at https://github.com/acartag7/gap-benchmark", "summary": "Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: does alignment that suppresses harmful text also suppress harmful actions? We introduce the GAP benchmark, a systematic evaluation framework that measures divergence between text-level safety and tool-call-level safety in LLM agents. We test six frontier models across six regulated domains (pharmaceutical, financial, educational, employment, legal, and infrastructure), seven jailbreak scenarios per domain, three system prompt conditions (neutral, safety-reinforced, and tool-encouraging), and two prompt variants, producing 17,420 analysis-ready datapoints. Our central finding is that text safety does not transfer to tool-call safety. Across all six models, we observe instances where the model's text output refuses a harmful request while its tool calls simultaneously execute the forbidden action--a divergence we formalize as the GAP metric. Even under safety-reinforced system prompts, 219 such cases persist across all six models. System prompt wording exerts substantial influence on tool-call behavior: TC-safe rates span 21 percentage points for the most robust model and 57 for the most prompt-sensitive, with 16 of 18 pairwise ablation comparisons remaining significant after Bonferroni correction. Runtime governance contracts reduce information leakage in all six models but produce no detectable deterrent effect on forbidden tool-call attempts themselves. These results demonstrate that text-only safety evaluations are insufficient for assessing agent behavior and that tool-call safety requires dedicated measurement and mitigation.", "AI": {"tldr": "Text-level safety alignment in LLMs does not guarantee tool-call safety; models can refuse harmful requests in text while simultaneously executing forbidden actions through tool calls.", "motivation": "Current safety evaluations focus on text-level refusal behavior, but LLM agents increasingly interact with external systems through tool calls with real-world consequences. There's a critical gap in understanding whether text-level safety alignment transfers to tool-call safety.", "method": "Introduced GAP benchmark with systematic evaluation framework testing six frontier models across six regulated domains, seven jailbreak scenarios per domain, three system prompt conditions, and two prompt variants, producing 17,420 datapoints. Formalized GAP metric to measure divergence between text safety and tool-call safety.", "result": "Text safety does not transfer to tool-call safety. Models exhibited instances where text output refused harmful requests while tool calls simultaneously executed forbidden actions. 219 such cases persisted across all six models even under safety-reinforced prompts. System prompt wording significantly influenced tool-call behavior, with TC-safe rates varying by 21-57 percentage points. Runtime governance contracts reduced information leakage but had no deterrent effect on forbidden tool-call attempts.", "conclusion": "Text-only safety evaluations are insufficient for assessing agent behavior; tool-call safety requires dedicated measurement and mitigation strategies beyond current text-level alignment approaches."}}
{"id": "2602.17515", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17515", "abs": "https://arxiv.org/abs/2602.17515", "authors": ["Ziyi Zong", "Xin Dong", "Jinwu Xiang", "Daochun Li", "Zhan Tu"], "title": "RA-Nav: A Risk-Aware Navigation System Based on Semantic Segmentation for Aerial Robots in Unpredictable Environments", "comment": null, "summary": "Existing aerial robot navigation systems typically plan paths around static and dynamic obstacles, but fail to adapt when a static obstacle suddenly moves. Integrating environmental semantic awareness enables estimation of potential risks posed by suddenly moving obstacles. In this paper, we propose RA- Nav, a risk-aware navigation framework based on semantic segmentation. A lightweight multi-scale semantic segmentation network identifies obstacle categories in real time. These obstacles are further classified into three types: stationary, temporarily static, and dynamic. For each type, corresponding risk estimation functions are designed to enable real-time risk prediction, based on which a complete local risk map is constructed. Based on this map, the risk-informed path search algorithm is designed to guarantee planning that balances path efficiency and safety. Trajectory optimization is then applied to generate trajectories that are safe, smooth, and dynamically feasible. Comparative simulations demonstrate that RA-Nav achieves higher success rates than baselines in sudden obstacle state transition scenarios. Its effectiveness is further validated in simulations using real- world data.", "AI": {"tldr": "RA-Nav is a risk-aware aerial navigation framework that uses semantic segmentation to classify obstacles and predict their movement risks, enabling safer path planning when static obstacles suddenly start moving.", "motivation": "Existing aerial navigation systems fail to adapt when static obstacles suddenly move, creating safety risks. The paper aims to address this limitation by integrating environmental semantic awareness to estimate potential risks from suddenly moving obstacles.", "method": "Proposes RA-Nav framework with: 1) Lightweight multi-scale semantic segmentation network for real-time obstacle category identification; 2) Obstacle classification into stationary, temporarily static, and dynamic types; 3) Risk estimation functions for each obstacle type; 4) Local risk map construction; 5) Risk-informed path search algorithm balancing efficiency and safety; 6) Trajectory optimization for safe, smooth, dynamically feasible paths.", "result": "Comparative simulations show RA-Nav achieves higher success rates than baselines in sudden obstacle state transition scenarios. Effectiveness is further validated in simulations using real-world data.", "conclusion": "RA-Nav successfully addresses the limitation of existing navigation systems by incorporating semantic awareness and risk prediction, enabling safer aerial navigation when obstacles unexpectedly change their movement states."}}
{"id": "2602.16953", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16953", "abs": "https://arxiv.org/abs/2602.16953", "authors": ["Hejia Zhang", "Zhongming Yu", "Chia-Tung Ho", "Haoxing Ren", "Brucek Khailany", "Jishen Zhao"], "title": "LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation", "comment": null, "summary": "Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Building on this formulation, we introduce execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints. We further curate a reality-aligned benchmark adapted from an existing verification suite through a revised evaluation protocol. Using the proposed pipeline, a compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.", "AI": {"tldr": "LLM4Cov: An offline agent-learning framework for hardware verification that uses execution-validated data curation and policy-aware synthesis to enable scalable learning under execution constraints, achieving 69.2% coverage pass rate with a 4B-parameter model.", "motivation": "Execution-aware LLM agents for learning from tool feedback face challenges with expensive and slow feedback acquisition, making online reinforcement learning impractical. Hardware verification exemplifies this challenge due to reliance on industrial simulators and non-differentiable execution signals.", "method": "Proposes LLM4Cov framework that models verification as memoryless state transitions guided by deterministic evaluators. Introduces execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints.", "result": "A compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.", "conclusion": "LLM4Cov provides an effective offline agent-learning framework for hardware verification that addresses execution constraints through novel data curation and synthesis techniques, enabling efficient learning with smaller models while maintaining competitive performance."}}
{"id": "2602.17537", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17537", "abs": "https://arxiv.org/abs/2602.17537", "authors": ["Qilong Cheng", "Matthew Mackay", "Ali Bereyhi"], "title": "IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control", "comment": null, "summary": "Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.", "AI": {"tldr": "IRIS is a low-cost, 3D-printed 6-DOF robotic camera system that uses imitation learning to autonomously execute cinematic camera motions from human demonstrations.", "motivation": "Industrial robotic camera systems are expensive and complex, limiting adoption. There's a need for affordable, accessible platforms that can perform dynamic cinematic motions without requiring explicit geometric programming.", "method": "IRIS combines a lightweight, fully 3D-printed 6-DOF manipulator with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware, perceptually smooth camera trajectories directly from human demonstrations.", "result": "The complete platform costs under $1,000 USD, supports 1.5 kg payload, achieves ~1 mm repeatability, and demonstrates accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions in real-world experiments.", "conclusion": "IRIS successfully addresses the cost and complexity barriers of robotic camera systems by providing an affordable, learning-driven platform that can autonomously execute high-quality cinematic motions without explicit programming."}}
{"id": "2602.16958", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16958", "abs": "https://arxiv.org/abs/2602.16958", "authors": ["Xinhao Deng", "Jiaqing Wu", "Miao Chen", "Yue Xiao", "Ke Xu", "Qi Li"], "title": "Automating Agent Hijacking via Structural Template Injection", "comment": null, "summary": "Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which often yields low attack success rates and limited transferability to closed-source commercial models. In this paper, we propose Phantom, an automated agent hijacking framework built upon Structured Template Injection that targets the fundamental architectural mechanisms of LLM agents. Our key insight is that agents rely on specific chat template tokens to separate system, user, assistant, and tool instructions. By injecting optimized structured templates into the retrieved context, we induce role confusion and cause the agent to misinterpret the injected content as legitimate user instructions or prior tool outputs. To enhance attack transferability against black-box agents, Phantom introduces a novel attack template search framework. We first perform multi-level template augmentation to increase structural diversity and then train a Template Autoencoder (TAE) to embed discrete templates into a continuous, searchable latent space. Subsequently, we apply Bayesian optimization to efficiently identify optimal adversarial vectors that are decoded into high-potency structured templates. Extensive experiments on Qwen, GPT, and Gemini demonstrate that our framework significantly outperforms existing baselines in both Attack Success Rate (ASR) and query efficiency. Moreover, we identified over 70 vulnerabilities in real-world commercial products that have been confirmed by vendors, underscoring the practical severity of structured template-based hijacking and providing an empirical foundation for securing next-generation agentic systems.", "AI": {"tldr": "Phantom is an automated agent hijacking framework using Structured Template Injection to exploit LLM agent architecture vulnerabilities, achieving high attack success rates and transferability across commercial models.", "motivation": "Existing agent hijacking attacks rely on manual prompt manipulation with low success rates and poor transferability to closed-source models. The OWASP-identified threat requires more effective exploitation of fundamental LLM agent architectural mechanisms.", "method": "Phantom uses Structured Template Injection targeting LLM agent chat template tokens. It employs multi-level template augmentation, trains a Template Autoencoder (TAE) to embed templates in continuous latent space, and uses Bayesian optimization to find optimal adversarial vectors decoded into high-potency structured templates.", "result": "Phantom significantly outperforms baselines in Attack Success Rate (ASR) and query efficiency on Qwen, GPT, and Gemini. Identified over 70 vulnerabilities in real-world commercial products confirmed by vendors.", "conclusion": "Structured template-based hijacking poses severe practical threats to LLM agents, requiring architectural defenses. Phantom provides empirical foundation for securing next-generation agentic systems against such attacks."}}
{"id": "2602.17573", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17573", "abs": "https://arxiv.org/abs/2602.17573", "authors": ["Konstantinos Foteinos", "Georgios Angelidis", "Aggelos Psiris", "Vasileios Argyriou", "Panagiotis Sarigiannidis", "Georgios Th. Papadopoulos"], "title": "FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations", "comment": null, "summary": "The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: https://doi.org/10.5281/zenodo.18131333.", "AI": {"tldr": "FR-GESTURE dataset for gesture-based UGV control by First Responders, featuring 12 commands, 3312 RGBD pairs from 2 viewpoints and 7 distances, with baseline experiments and public availability.", "motivation": "Increasing disaster intensity and frequency makes First Responders' work more difficult; AI and robotics solutions could facilitate operations by enabling gesture-based unmanned ground vehicle control.", "method": "Created dataset with 12 commands inspired by existing FR gestures and tactical hand signals, refined with FR feedback; collected 3312 RGBD pairs from 2 viewpoints and 7 distances; defined evaluation protocols and performed baseline experiments.", "result": "First dataset specifically for gesture-based UGV guidance by First Responders; data publicly available at https://doi.org/10.5281/zenodo.18131333; baseline experiments established for future improvement.", "conclusion": "FR-GESTURE dataset addresses the need for gesture-based UGV control systems for First Responders, providing foundational data and benchmarks to advance research in disaster response robotics."}}
{"id": "2602.16976", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16976", "abs": "https://arxiv.org/abs/2602.16976", "authors": ["Srikumar Nayak"], "title": "HQFS: Hybrid Quantum Classical Financial Security with VQC Forecasting, QUBO Annealing, and Audit-Ready Post-Quantum Signing", "comment": "11 pages, 1 fig , 4 tables", "summary": "Here's the corrected paragraph with all punctuation and formatting issues fixed:\n  Financial risk systems usually follow a two-step routine: a model predicts return or risk, and then an optimizer makes a decision such as a portfolio rebalance. In practice, this split can break under real constraints. The prediction model may look good, but the final decision can be unstable when the market shifts, when discrete constraints are added (lot sizes, caps), or when the optimization becomes slow for larger asset sets. Also, regulated settings need a clear audit trail that links each decision to the exact model state and inputs. We present HQFS, a practical hybrid pipeline that connects forecasting, discrete risk optimization, and auditability in one flow. First, HQFS learns next-step return and a volatility proxy using a variational quantum circuit (VQC) with a small classical head. Second, HQFS converts the risk-return objective and constraints into a QUBO and solves it with quantum annealing when available, while keeping a compatible classical QUBO solver as a fallback for deployment. Third, HQFS signs each rebalance output using a post-quantum signature so the allocation can be verified later without trusting the runtime environment. On our market dataset study, HQFS reduces return prediction error by 7.8% and volatility prediction error by 6.1% versus a tuned classical baseline. For the decision layer, HQFS improves out-of-sample Sharpe by 9.4% and lowers maximum drawdown by 11.7%. The QUBO solve stage also cuts average solve time by 28% compared to a mixed-integer baseline under the same constraints, while producing fully traceable, signed allocation records.", "AI": {"tldr": "HQFS is a hybrid quantum-classical pipeline for financial risk systems that integrates forecasting, discrete risk optimization, and auditability in a unified flow, improving prediction accuracy, portfolio performance, and solve times while providing verifiable allocation records.", "motivation": "Traditional two-step financial risk systems (prediction followed by optimization) break under real constraints: predictions may look good but final decisions become unstable with market shifts, discrete constraints (lot sizes, caps), or slow optimization for large asset sets. Regulated settings also require clear audit trails linking decisions to exact model states and inputs.", "method": "HQFS uses a three-stage hybrid pipeline: 1) Learns next-step return and volatility proxy using variational quantum circuit (VQC) with small classical head; 2) Converts risk-return objective and constraints into QUBO, solving with quantum annealing when available (classical QUBO solver as fallback); 3) Signs each rebalance output using post-quantum signature for later verification without trusting runtime environment.", "result": "On market dataset: reduces return prediction error by 7.8% and volatility prediction error by 6.1% vs tuned classical baseline. Decision layer improves out-of-sample Sharpe by 9.4% and lowers maximum drawdown by 11.7%. QUBO solve stage cuts average solve time by 28% vs mixed-integer baseline under same constraints, while producing fully traceable, signed allocation records.", "conclusion": "HQFS provides a practical solution that addresses the limitations of traditional split prediction-optimization pipelines by integrating forecasting, discrete risk optimization, and auditability in a unified flow, demonstrating improved performance, efficiency, and regulatory compliance for financial risk systems."}}
{"id": "2602.17574", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17574", "abs": "https://arxiv.org/abs/2602.17574", "authors": ["Joshua A. Robbins", "Andrew F. Thompson", "Jonah J. Glunt", "Herschel C. Pangborn"], "title": "Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes", "comment": null, "summary": "Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.", "AI": {"tldr": "Hybrid zonotopes + ADMM heuristic for efficient embedded motion planning of hybrid systems, with applications to autonomous driving.", "motivation": "Embedded optimization-based planning for hybrid systems is computationally intensive due to mixed-integer programming, which is sensitive to numerical formulation and challenging for real-time applications.", "method": "Pairs hybrid zonotopes (advanced set representation) with a new ADMM mixed-integer programming heuristic; presents general treatment of piecewise affine system reachability analysis using hybrid zonotopes and extends to formulate optimal planning problems.", "result": "Sets produced using proposed identities have lower memory complexity and tighter convex relaxations than preexisting techniques; ADMM heuristic achieves improved convergence rates compared to state-of-the-art mixed-integer programming heuristics.", "conclusion": "Proposed framework enables efficient hybrid system planning on embedded hardware, demonstrated experimentally in combined behavior and motion planning for autonomous driving."}}
{"id": "2602.16984", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16984", "abs": "https://arxiv.org/abs/2602.16984", "authors": ["Vishal Srivastava"], "title": "Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning", "comment": null, "summary": "Black-box safety evaluation of AI systems assumes model behavior on test distributions reliably predicts deployment performance. We formalize and challenge this assumption through latent context-conditioned policies -- models whose outputs depend on unobserved internal variables that are rare under evaluation but prevalent under deployment. We establish fundamental limits showing that no black-box evaluator can reliably estimate deployment risk for such models. (1) Passive evaluation: For evaluators sampling i.i.d. from D_eval, we prove minimax lower bounds via Le Cam's method: any estimator incurs expected absolute error >= (5/24)*delta*L approximately 0.208*delta*L, where delta is trigger probability under deployment and L is the loss gap. (2) Adaptive evaluation: Using a hash-based trigger construction and Yao's minimax principle, worst-case error remains >= delta*L/16 even for fully adaptive querying when D_dep is supported over a sufficiently large domain; detection requires Theta(1/epsilon) queries. (3) Computational separation: Under trapdoor one-way function assumptions, deployment environments possessing privileged information can activate unsafe behaviors that any polynomial-time evaluator without the trapdoor cannot distinguish. For white-box probing, estimating deployment risk to accuracy epsilon_R requires O(1/(gamma^2 * epsilon_R^2)) samples, where gamma = alpha_0 + alpha_1 - 1 measures probe quality, and we provide explicit bias correction under probe error. Our results quantify when black-box testing is statistically underdetermined and provide explicit criteria for when additional safeguards -- architectural constraints, training-time guarantees, interpretability, and deployment monitoring -- are mathematically necessary for worst-case safety assurance.", "AI": {"tldr": "Black-box safety evaluation fails for models with latent context-conditioned policies due to fundamental statistical limits, requiring additional safeguards beyond testing.", "motivation": "To challenge the assumption that black-box safety evaluation reliably predicts deployment performance, especially for models with unobserved internal variables that are rare during evaluation but prevalent during deployment.", "method": "Formal analysis using latent context-conditioned policies, statistical minimax lower bounds via Le Cam's method, adaptive evaluation analysis with hash-based triggers and Yao's minimax principle, computational separation under trapdoor one-way function assumptions, and white-box probing with bias correction.", "result": "Fundamental limits show no black-box evaluator can reliably estimate deployment risk: passive evaluation has error \u2265 0.208\u03b4L, adaptive evaluation has error \u2265 \u03b4L/16, computational separation prevents polynomial-time detection, while white-box probing requires O(1/(\u03b3\u00b2\u03b5_R\u00b2)) samples.", "conclusion": "Black-box testing is statistically underdetermined for latent context-conditioned policies, necessitating additional safeguards like architectural constraints, training-time guarantees, interpretability, and deployment monitoring for worst-case safety assurance."}}
{"id": "2602.17586", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17586", "abs": "https://arxiv.org/abs/2602.17586", "authors": ["Antonio Guillen-Perez"], "title": "Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space", "comment": null, "summary": "Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.", "AI": {"tldr": "Deep-Flow: Unsupervised safety-critical anomaly detection for AVs using Optimal Transport Conditional Flow Matching on low-rank spectral manifolds, achieving 0.766 AUC-ROC on WOMD and revealing distinction between kinematic danger and semantic non-compliance.", "motivation": "Safety validation for Level 4 AVs is bottlenecked by inability to scale detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. Current approaches struggle with unstable high-dimensional spaces and fail to distinguish between different types of safety violations.", "method": "Uses Optimal Transport Conditional Flow Matching (OT-CFM) to characterize continuous probability density of expert human driving behavior. Constrains generative process to low-rank spectral manifold via PCA bottleneck for kinematic smoothness. Employs Early Fusion Transformer encoder with lane-aware goal conditioning and direct skip-connection to flow head. Introduces kinematic complexity weighting scheme prioritizing high-energy maneuvers during training.", "result": "Achieves AUC-ROC of 0.766 on Waymo Open Motion Dataset against heuristic golden set of safety-critical events. Reveals fundamental distinction between kinematic danger and semantic non-compliance. Identifies predictability gap by surfacing out-of-distribution behaviors (lane-boundary violations, non-normative junction maneuvers) that traditional safety filters overlook.", "conclusion": "Provides mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for safe deployment of autonomous fleets. Framework offers unsupervised approach to detect safety-critical anomalies beyond traditional rule-based methods."}}
{"id": "2602.16990", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2602.16990", "abs": "https://arxiv.org/abs/2602.16990", "authors": ["Yan Wang", "Yi Han", "Lingfei Qian", "Yueru He", "Xueqing Peng", "Dongji Feng", "Zhuohan Xie", "Vincent Jim Zhang", "Rosie Guo", "Fengran Mo", "Jimin Huang", "Yankai Chen", "Xue Liu", "Jian-Yun Nie"], "title": "Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation", "comment": null, "summary": "Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, a conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over a fixed investment horizon. Crucially, Conv-FinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate a suite of state-of-the-art LLMs. Results reveal a persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face, and the codebase is available on GitHub.", "AI": {"tldr": "Conv-FinRe is a conversational benchmark for stock recommendation that evaluates LLMs on decision quality rather than just behavior imitation, using multi-view references to distinguish rational analysis from user noise.", "motivation": "Existing recommendation benchmarks focus on imitating user behavior, but in financial advisory, observed actions can be noisy or short-sighted under market volatility and may conflict with long-term goals. Treating user choices as ground truth conflates behavioral imitation with decision quality.", "method": "Introduces Conv-FinRe, a conversational and longitudinal benchmark built from real market data and human decision trajectories. It includes onboarding interviews, step-wise market context, and advisory dialogues where models must generate rankings over fixed investment horizons. Provides multi-view references distinguishing descriptive behavior from normative utility grounded in investor-specific risk preferences.", "result": "Evaluation of state-of-the-art LLMs reveals a persistent tension between rational decision quality and behavioral alignment: models performing well on utility-based ranking often fail to match user choices, while behaviorally aligned models can overfit short-term noise. Dataset is publicly released on Hugging Face with codebase on GitHub.", "conclusion": "Conv-FinRe enables diagnosis of whether LLMs follow rational analysis, mimic user noise, or are driven by market momentum, moving beyond behavior matching to evaluate decision quality in financial advisory contexts."}}
{"id": "2602.17601", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17601", "abs": "https://arxiv.org/abs/2602.17601", "authors": ["Patrick Benito Eberhard", "Luis Pabon", "Daniele Gammelli", "Hugo Buurmeijer", "Amon Lahr", "Mark Leone", "Andrea Carron", "Marco Pavone"], "title": "Graph Neural Model Predictive Control for High-Dimensional Systems", "comment": null, "summary": "The control of high-dimensional systems, such as soft robots, requires models that faithfully capture complex dynamics while remaining computationally tractable. This work presents a framework that integrates Graph Neural Network (GNN)-based dynamics models with structure-exploiting Model Predictive Control to enable real-time control of high-dimensional systems. By representing the system as a graph with localized interactions, the GNN preserves sparsity, while a tailored condensing algorithm eliminates state variables from the control problem, ensuring efficient computation. The complexity of our condensing algorithm scales linearly with the number of system nodes, and leverages Graphics Processing Unit (GPU) parallelization to achieve real-time performance. The proposed approach is validated in simulation and experimentally on a physical soft robotic trunk. Results show that our method scales to systems with up to 1,000 nodes at 100 Hz in closed-loop, and demonstrates real-time reference tracking on hardware with sub-centimeter accuracy, outperforming baselines by 63.6%. Finally, we show the capability of our method to achieve effective full-body obstacle avoidance.", "AI": {"tldr": "A framework combining GNN-based dynamics models with structure-exploiting MPC enables real-time control of high-dimensional systems like soft robots, achieving 100Hz closed-loop performance with 1000 nodes and sub-centimeter tracking accuracy.", "motivation": "High-dimensional systems like soft robots require models that capture complex dynamics while remaining computationally tractable for real-time control applications.", "method": "Integration of Graph Neural Network (GNN)-based dynamics models with structure-exploiting Model Predictive Control (MPC). The system is represented as a graph with localized interactions, and a tailored condensing algorithm eliminates state variables while preserving sparsity. The algorithm scales linearly with system nodes and leverages GPU parallelization.", "result": "The method scales to systems with up to 1,000 nodes at 100 Hz in closed-loop, demonstrates real-time reference tracking on hardware with sub-centimeter accuracy (outperforming baselines by 63.6%), and achieves effective full-body obstacle avoidance.", "conclusion": "The proposed framework successfully enables real-time control of high-dimensional systems by combining GNN-based modeling with efficient MPC, validated through simulation and physical experiments on a soft robotic trunk."}}
{"id": "2602.17001", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.17001", "abs": "https://arxiv.org/abs/2602.17001", "authors": ["Zhao Tan", "Yiji Zhao", "Shiyu Wang", "Chang Xu", "Yuxuan Liang", "Xiping Liu", "Shirui Pan", "Ming Jin"], "title": "Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases", "comment": null, "summary": "Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, while time series models struggle to handle ultra-long histories. To address these challenges, we propose Sonar-TS, a neuro-symbolic framework that tackles NLQ4TSDB via a Search-Then-Verify pipeline. Analogous to active sonar, it utilizes a feature index to ping candidate windows via SQL, followed by generated Python programs to lock on and verify candidates against raw signals. To enable effective evaluation, we introduce NLQTSBench, the first large-scale benchmark designed for NLQ over TSDB-scale histories. Our experiments highlight the unique challenges within this domain and demonstrate that Sonar-TS effectively navigates complex temporal queries where traditional methods fail. This work presents the first systematic study of NLQ4TSDB, offering a general framework and evaluation standard to facilitate future research.", "AI": {"tldr": "Sonar-TS is a neuro-symbolic framework for natural language querying of time series databases that uses a Search-Then-Verify pipeline with SQL for candidate window retrieval and Python programs for verification against raw signals, evaluated on the new NLQTSBench benchmark.", "motivation": "Existing Text-to-SQL methods cannot handle continuous morphological intents (shapes, anomalies) in time series data, while time series models struggle with ultra-long histories, creating a gap for natural language querying of time series databases.", "method": "Sonar-TS uses a neuro-symbolic Search-Then-Verify pipeline: 1) Feature indexing for candidate window retrieval via SQL queries, 2) Generated Python programs to verify candidates against raw signals, analogous to active sonar's ping-and-lock approach.", "result": "The paper introduces NLQTSBench, the first large-scale benchmark for NLQ over TSDB-scale histories. Experiments show Sonar-TS effectively handles complex temporal queries where traditional methods fail, demonstrating unique challenges in this domain.", "conclusion": "This work presents the first systematic study of NLQ4TSDB, offering a general neuro-symbolic framework and evaluation standard to facilitate future research in natural language querying for time series databases."}}
{"id": "2602.17049", "categories": ["cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17049", "abs": "https://arxiv.org/abs/2602.17049", "authors": ["Seoyoung Lee", "Seobin Yoon", "Seongbeen Lee", "Yoojung Chun", "Dayoung Park", "Doyeon Kim", "Joo Yong Sim"], "title": "IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents", "comment": "12 pages, 9 figures, AAMAS 2026", "summary": "Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.", "AI": {"tldr": "IntentCUA: A multi-agent framework for long-horizon computer-use automation that uses intent-aligned plan memory to stabilize execution and reduce redundant re-planning.", "motivation": "Existing computer-use agents suffer from error accumulation and inefficiency due to drifting from user intent and repeatedly solving routine subproblems in noisy, multi-window environments with evolving states.", "method": "Multi-agent framework with Planner, Plan-Optimizer, and Critic coordinating over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. Intent prototypes retrieve subgroup-aligned skills and inject them into partial plans.", "result": "Achieved 74.83% task success rate with Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Multi-view intent abstraction and shared plan memory jointly improve execution stability.", "conclusion": "System-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments, with cooperative multi-agent loops providing largest gains on long-horizon tasks."}}
{"id": "2602.17015", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.17015", "abs": "https://arxiv.org/abs/2602.17015", "authors": ["Saurav Pal"], "title": "Cinder: A fast and fair matchmaking system", "comment": null, "summary": "A fair and fast matchmaking system is an important component of modern multiplayer online games, directly impacting player retention and satisfaction. However, creating fair matches between lobbies (pre-made teams) of heterogeneous skill levels presents a significant challenge. Matching based simply on average team skill metrics, such as mean or median rating or rank, often results in unbalanced and one-sided games, particularly when skill distributions are wide or skewed. This paper introduces Cinder, a two-stage matchmaking system designed to provide fast and fair matches. Cinder first employs a rapid preliminary filter by comparing the \"non-outlier\" skill range of lobbies using the Ruzicka similarity index. Lobbies that pass this initial check are then evaluated using a more precise fairness metric. This second stage involves mapping player ranks to a non-linear set of skill buckets, generated from an inverted normal distribution, to provide higher granularity at average skill levels. The fairness of a potential match is then quantified using the Kantorovich distance on the lobbies' sorted bucket indices, producing a \"Sanction Score.\" We demonstrate the system's viability by analyzing the distribution of Sanction Scores from 140 million simulated lobby pairings, providing a robust foundation for fair matchmaking thresholds.", "AI": {"tldr": "Cinder is a two-stage matchmaking system for multiplayer games that uses Ruzicka similarity for initial filtering and Kantorovich distance on skill buckets for precise fairness evaluation.", "motivation": "Traditional matchmaking based on average team skill metrics often results in unbalanced games, especially with heterogeneous skill levels in pre-made teams (lobbies), impacting player retention and satisfaction.", "method": "Two-stage system: 1) Rapid preliminary filter using Ruzicka similarity index on \"non-outlier\" skill ranges; 2) Precise fairness evaluation mapping player ranks to non-linear skill buckets (inverted normal distribution) and calculating Kantorovich distance on sorted bucket indices to produce a \"Sanction Score.\"", "result": "Demonstrated viability by analyzing distribution of Sanction Scores from 140 million simulated lobby pairings, providing foundation for fair matchmaking thresholds.", "conclusion": "Cinder provides a robust approach for fast and fair matchmaking that addresses limitations of traditional average-based methods, particularly for lobbies with heterogeneous skill distributions."}}
{"id": "2602.17016", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17016", "abs": "https://arxiv.org/abs/2602.17016", "authors": ["Zichen Wang", "Wanli Ma", "Zhenyu Ming", "Gong Zhang", "Kun Yuan", "Zaiwen Wen"], "title": "M2F: Automated Formalization of Mathematical Literature at Scale", "comment": null, "summary": "Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects compile end-to-end. We present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization in Lean. The framework operates in two stages. The statement compilation stage splits the document into atomic blocks, orders them via inferred dependencies, and repairs declaration skeletons until the project compiles, allowing placeholders in proofs. The proof repair stage closes these holes under fixed signatures using goal-conditioned local edits. Throughout both stages, M2F keeps the verifier in the loop, committing edits only when toolchain feedback confirms improvement. In approximately three weeks, M2F converts long-form mathematical sources into a project-scale Lean library of 153,853 lines from 479 pages textbooks on real analysis and convex analysis, fully formalized as Lean declarations with accompanying proofs. This represents textbook-scale formalization at a pace that would typically require months or years of expert effort. On FATE-H, we achieve $96\\%$ proof success (vs.\\ $80\\%$ for a strong baseline). Together, these results demonstrate that practical, large-scale automated formalization of mathematical literature is within reach. The full generated Lean code from our runs is available at https://github.com/optsuite/ReasBook.git.", "code_url": "https://github.com/optsuite/ReasBook", "code_stars": 0, "code_last_update": "2026-02-18", "AI": {"tldr": "M2F is an agentic framework for end-to-end, project-scale autoformalization in Lean that converts textbook mathematics into fully verified Lean code with high success rates.", "motivation": "Current automated formalization is limited to isolated theorems and short snippets, lacking the ability to scale to entire textbooks and research papers which require managing cross-file dependencies, resolving imports, and ensuring end-to-end compilation of entire projects.", "method": "Two-stage framework: (1) Statement compilation stage splits documents into atomic blocks, orders them via inferred dependencies, and repairs declaration skeletons until project compiles (allowing placeholders in proofs); (2) Proof repair stage closes proof holes under fixed signatures using goal-conditioned local edits. Both stages keep the verifier in the loop, committing edits only when toolchain feedback confirms improvement.", "result": "In ~3 weeks, converted 479 pages of textbooks on real analysis and convex analysis into a 153,853-line Lean library. Achieved 96% proof success on FATE-H benchmark (vs. 80% for strong baseline), demonstrating textbook-scale formalization at a pace that would typically require months or years of expert effort.", "conclusion": "Practical, large-scale automated formalization of mathematical literature is within reach, as demonstrated by M2F's ability to handle project-scale formalization with high success rates and significant time savings compared to manual expert effort."}}
{"id": "2602.17017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17017", "abs": "https://arxiv.org/abs/2602.17017", "authors": ["Deepanjan Bhol"], "title": "Sales Research Agent and Sales Research Bench", "comment": "Technical report. 2 figures. Microsoft Dynamics 365 Sales", "summary": "Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. To make quality observable, we introduce the Sales Research Bench, a purpose-built benchmark that scores systems on eight customer-weighted dimensions, including text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question run on a customized enterprise schema on October 19, 2025, the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score, giving customers a repeatable way to compare AI solutions.", "AI": {"tldr": "Sales Research Agent in Microsoft Dynamics 365 Sales outperforms leading AI models on enterprise CRM data analysis using a purpose-built benchmark with 8 quality dimensions.", "motivation": "Enterprises need AI systems that can answer sales-leader questions over live CRM data, but most models lack transparent, repeatable evidence of quality, making it difficult to compare AI solutions for enterprise use.", "method": "Developed Sales Research Agent that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. Created Sales Research Bench benchmark that scores systems on eight customer-weighted dimensions: text/chart groundedness, relevance, explainability, schema accuracy, and chart quality.", "result": "In a 200-question evaluation on a customized enterprise schema (Oct 19, 2025), the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score.", "conclusion": "The Sales Research Agent provides enterprises with an AI solution that delivers transparent, repeatable quality evidence for CRM data analysis, enabling customers to reliably compare AI solutions through a standardized benchmark."}}
{"id": "2602.17038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17038", "abs": "https://arxiv.org/abs/2602.17038", "authors": ["Shengtian Yang", "Yu Li", "Shuo He", "Yewen Li", "Qingpeng Cai", "Peng Jiang", "Lei Feng"], "title": "Phase-Aware Mixture of Experts for Agentic Reinforcement Learning", "comment": "16 pages", "summary": "Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \\emph{single} policy network, causing \\emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leaving insufficient capacity for complex tasks. A plausible remedy could be employing the Mixture-of-Experts (MoE) architecture in the policy network, as MoE allows different parameters (experts) to specialize in different tasks, preventing simple tasks from dominating all parameters. However, a key limitation of traditional MoE is its token-level routing, where the router assigns each token to specialized experts, which fragments phase-consistent patterns into scattered expert assignments and thus undermines expert specialization. In this paper, we propose \\textbf{Phase-Aware Mixture of Experts (PA-MoE)}. It first features a lightweight \\emph{phase router} that learns latent phase boundaries directly from the RL objective without pre-defining phase categories. Then, the phase router allocates temporally consistent assignments to the same expert, allowing experts to preserve phase-specific expertise. Experimental results demonstrate the effectiveness of our proposed PA-MoE.", "AI": {"tldr": "PA-MoE introduces phase-aware routing in RL policy networks to prevent simple tasks from dominating parameters and enable expert specialization for complex tasks.", "motivation": "Existing RL methods with single policy networks suffer from simplicity bias where simple tasks dominate gradient updates, leaving insufficient capacity for complex tasks. Traditional MoE's token-level routing fragments phase-consistent patterns, undermining expert specialization.", "method": "Proposes Phase-Aware Mixture of Experts (PA-MoE) with a lightweight phase router that learns latent phase boundaries directly from RL objective without pre-defined categories, allocating temporally consistent assignments to the same expert to preserve phase-specific expertise.", "result": "Experimental results demonstrate the effectiveness of the proposed PA-MoE approach.", "conclusion": "PA-MoE addresses the limitations of both single-policy RL networks and traditional MoE by enabling phase-aware expert specialization through learned phase boundaries and temporally consistent routing."}}
{"id": "2602.17046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17046", "abs": "https://arxiv.org/abs/2602.17046", "authors": ["Uria Franko"], "title": "Dynamic System Instructions and Tool Exposure for Efficient Agentic LLMs", "comment": null, "summary": "Large Language Model (LLM) agents often run for many steps while re-ingesting long system instructions and large tool catalogs each turn. This increases cost, agent derailment probability, latency, and tool-selection errors. We propose Instruction-Tool Retrieval (ITR), a RAG variant that retrieves, per step, only the minimal system-prompt fragments and the smallest necessary subset of tools. ITR composes a dynamic runtime system prompt and exposes a narrowed toolset with confidence-gated fallbacks. Using a controlled benchmark with internally consistent numbers, ITR reduces per-step context tokens by 95%, improves correct tool routing by 32% relative, and cuts end-to-end episode cost by 70% versus a monolithic baseline. These savings enable agents to run 2-20x more loops within context limits. Savings compound with the number of agent steps, making ITR particularly valuable for long-running autonomous agents. We detail the method, evaluation protocol, ablations, and operational guidance for practical deployment.", "AI": {"tldr": "ITR (Instruction-Tool Retrieval) reduces LLM agent costs by 70% and improves tool routing by 32% through dynamic retrieval of only necessary system instructions and tools per step.", "motivation": "LLM agents suffer from high costs, latency, and errors due to repeatedly processing long system instructions and large tool catalogs at every step, increasing derailment probability and tool-selection errors.", "method": "ITR is a RAG variant that retrieves minimal system-prompt fragments and the smallest necessary subset of tools per step, composing a dynamic runtime system prompt with narrowed toolset and confidence-gated fallbacks.", "result": "ITR reduces per-step context tokens by 95%, improves correct tool routing by 32% relative, cuts end-to-end episode cost by 70%, and enables agents to run 2-20x more loops within context limits.", "conclusion": "ITR provides substantial efficiency gains for LLM agents, with savings compounding over multiple steps, making it particularly valuable for long-running autonomous agents."}}
{"id": "2602.17053", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17053", "abs": "https://arxiv.org/abs/2602.17053", "authors": ["Yunseok Han", "Yejoon Lee", "Jaeyoung Do"], "title": "RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models", "comment": "Accepted in ICLR 2026 Poster: $\\href{https://iclr.cc/virtual/2026/poster/10011763}{\\text{this URL}}$", "summary": "Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consistency (a coherent stance linking reasoning to answer) and causal influence (the stated reasoning causally drives the answer under output-level interventions), explicitly decoupled from accuracy. To operationalize this, we present RFEval, a benchmark of 7,186 instances across seven tasks that probes faithfulness via controlled, output-level counterfactual interventions. Evaluating twelve open-source LRMs, we find unfaithfulness in 49.7% of outputs, predominantly from stance inconsistency. Failures are concentrated in brittle, convergent domains such as math and code, and correlate more with post-training regimes than with scale: within-family ablations indicate that adding current RL-style objectives on top of supervised fine-tuning can reduce reasoning faithfulness, even when accuracy is maintained. Crucially, accuracy is neither a sufficient nor a reliable proxy for faithfulness: once controlling for model and task, the accuracy-faithfulness link is weak and statistically insignificant. Our work establishes a rigorous methodology for auditing LRM reliability and shows that trustworthy AI requires optimizing not only for correct outcomes but also for the structural integrity of the reasoning process. Our code and dataset can be found at project page: $\\href{https://aidaslab.github.io/RFEval/}{https://aidaslab.github.io/RFEval/}$", "code_url": "https://aidaslab.github.io/RFEval", "AI": {"tldr": "RFEval benchmark reveals 49.7% unfaithful reasoning in Large Reasoning Models, showing accuracy is not a reliable proxy for faithfulness, with RL-style objectives potentially reducing reasoning integrity.", "motivation": "Large Reasoning Models often produce plausible-sounding rationales that don't reflect their true decision process, undermining reliability and trust. Current evaluation focuses on accuracy but neglects reasoning faithfulness.", "method": "Introduce formal framework for reasoning faithfulness with two testable conditions: stance consistency and causal influence. Create RFEval benchmark with 7,186 instances across seven tasks using controlled output-level counterfactual interventions to probe faithfulness.", "result": "Evaluating 12 open-source LRMs reveals unfaithfulness in 49.7% of outputs, predominantly from stance inconsistency. Failures concentrate in math and code domains. RL-style objectives on top of supervised fine-tuning reduce faithfulness even when accuracy is maintained. Accuracy-faithfulness correlation is weak and statistically insignificant.", "conclusion": "Trustworthy AI requires optimizing for both correct outcomes and structural integrity of reasoning. RFEval provides rigorous methodology for auditing LRM reliability, showing current training regimes may compromise reasoning faithfulness despite maintaining accuracy."}}
{"id": "2602.17062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17062", "abs": "https://arxiv.org/abs/2602.17062", "authors": ["Yonghyeon Jo", "Sunwoo Lee", "Seungyul Han"], "title": "Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning", "comment": "10 technical page followed by references and appendix. Accepted to ICLR 2026", "summary": "Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\\text{tot}}$ to adjust quickly to the changing optima. Experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance. Our code is available at https://github.com/hyeon1996/S2Q.", "code_url": "https://github.com/hyeon1996/S2Q", "code_stars": 0, "code_last_update": "2026-02-19", "AI": {"tldr": "S2Q is a new MARL method that learns multiple sub-value functions to retain alternative high-value actions, enabling better adaptation to shifting value functions and improved exploration.", "motivation": "Existing value decomposition methods in MARL rely on single optimal actions and struggle to adapt when value functions shift during training, often converging to suboptimal policies.", "method": "Successive Sub-value Q-learning (S2Q) learns multiple sub-value functions to retain alternative high-value actions, incorporates them into a Softmax-based behavior policy to encourage persistent exploration, and enables Q^tot to adjust quickly to changing optima.", "result": "Experiments on challenging MARL benchmarks show S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance.", "conclusion": "S2Q addresses limitations of existing value decomposition methods by learning multiple sub-value functions, enabling better adaptation to shifting value functions and improved performance in cooperative multi-agent reinforcement learning."}}
{"id": "2602.17066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17066", "abs": "https://arxiv.org/abs/2602.17066", "authors": ["Sumedh Rasal"], "title": "Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization", "comment": null, "summary": "We introduce Predictive Batch Scheduling (PBS), a novel training optimization technique that accelerates language model convergence by dynamically prioritizing high-loss samples during batch construction. Unlike curriculum learning approaches that require predefined difficulty metrics or hard example mining methods that demand expensive per-sample loss tracking, PBS employs a lightweight linear predictor trained online to estimate sample difficulty from static token-level features. Our predictor achieves 0.44 correlation with actual loss using only four simple features: token frequency, sequence length, vocabulary diversity, and rare token ratio. Experiments on a 130M parameter transformer demonstrate that PBS achieves 6-13\\% faster convergence measured by evaluation loss across training checkpoints, with the predictor's correlation improving from 0.14 to 0.44 over 10,000 training steps. These results validate that token frequency statistics encode meaningful information about sample difficulty, enabling effective curriculum learning with negligible computational overhead.", "AI": {"tldr": "PBS is a lightweight training optimization technique that accelerates language model convergence by using a linear predictor to prioritize high-loss samples during batch construction based on token-level features.", "motivation": "Existing curriculum learning approaches require predefined difficulty metrics, while hard example mining methods need expensive per-sample loss tracking. There's a need for an efficient way to identify difficult training samples without significant computational overhead.", "method": "PBS uses a lightweight linear predictor trained online to estimate sample difficulty from four static token-level features: token frequency, sequence length, vocabulary diversity, and rare token ratio. The predictor dynamically prioritizes high-loss samples during batch construction.", "result": "The predictor achieves 0.44 correlation with actual loss using only four features. Experiments on a 130M parameter transformer show 6-13% faster convergence measured by evaluation loss across training checkpoints. Predictor correlation improves from 0.14 to 0.44 over 10,000 training steps.", "conclusion": "Token frequency statistics encode meaningful information about sample difficulty, enabling effective curriculum learning with negligible computational overhead. PBS provides a practical alternative to traditional curriculum learning and hard example mining methods."}}
{"id": "2602.17084", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17084", "abs": "https://arxiv.org/abs/2602.17084", "authors": ["Kan Watanabe", "Rikuto Tsuchida", "Takahiro Monno", "Bin Huang", "Kazuma Yamasaki", "Youmei Fan", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses", "comment": null, "summary": "The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including structural features, and examine human reviewer response in terms of review activity, response timing, sentiment, and merge outcomes. We find that AI coding agents exhibit distinct PR description styles, which are associated with differences in reviewer engagement, response time, and merge outcomes. We observe notable variation across agents in both reviewer interaction metrics and merge rates. These findings highlight the role of pull request presentation and reviewer interaction dynamics in human-AI collaborative software development.", "AI": {"tldr": "Empirical analysis of AI coding agents' pull request characteristics and human reviewer responses reveals distinct PR description styles affecting reviewer engagement, response timing, and merge outcomes.", "motivation": "The rapid adoption of large language models has led to AI coding agents autonomously creating pull requests on GitHub, but how these agents differ in their pull request description characteristics and how human reviewers respond to them remains underexplored.", "method": "Conducted an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset, analyzing agent differences in pull request description characteristics (including structural features) and examining human reviewer response in terms of review activity, response timing, sentiment, and merge outcomes.", "result": "AI coding agents exhibit distinct PR description styles associated with differences in reviewer engagement, response time, and merge outcomes. Notable variation across agents in both reviewer interaction metrics and merge rates was observed.", "conclusion": "Findings highlight the role of pull request presentation and reviewer interaction dynamics in human-AI collaborative software development."}}
{"id": "2602.17096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17096", "abs": "https://arxiv.org/abs/2602.17096", "authors": ["Zhaoyang Li", "Xingzhi Jin", "Junyu Pan", "Qianqian Yang", "Zhiguo Shi"], "title": "Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence", "comment": null, "summary": "As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by multi-dimensional objectives such as latency sensitivity, energy preference, computational constraints, and service-level requirements. These objectives may also change over time due to environmental dynamics and user-network interactions. Therefore, accurate understanding of both the communication environment and user intent is critical for autonomous and sustainably evolving 6G communications.\n  Large language models (LLMs), with strong contextual understanding and cross-modal reasoning, provide a promising foundation for intent-aware network agents. Compared with rule-driven or centrally optimized designs, LLM-based agents can integrate heterogeneous information and translate natural-language intents into executable control and configuration decisions.\n  Focusing on a closed-loop pipeline of intent perception, autonomous decision making, and network execution, this paper investigates agentic AI for the 6G physical layer and its realization pathways. We review representative physical-layer tasks and their limitations in supporting intent awareness and autonomy, identify application scenarios where agentic AI is advantageous, and discuss key challenges and enabling technologies in multimodal perception, cross-layer decision making, and sustainable optimization. Finally, we present a case study of an intent-driven link decision agent, termed AgenCom, which adaptively constructs communication links under diverse user preferences and channel conditions.", "AI": {"tldr": "This paper proposes using LLM-based agentic AI for intent-driven autonomous 6G physical layer networks, addressing multi-dimensional user objectives and dynamic requirements through a closed-loop pipeline of intent perception, decision making, and network execution.", "motivation": "6G systems face growing functional complexity and diverse service demands that require moving beyond rule-based control to intent-driven autonomous intelligence. User requirements are now multi-dimensional (latency sensitivity, energy preference, computational constraints, service-level requirements) and dynamic, necessitating accurate understanding of both communication environment and user intent for sustainable 6G evolution.", "method": "The paper investigates agentic AI for 6G physical layer through a closed-loop pipeline of intent perception, autonomous decision making, and network execution. It reviews physical-layer tasks, identifies application scenarios where agentic AI is advantageous, discusses key challenges and enabling technologies in multimodal perception, cross-layer decision making, and sustainable optimization, and presents a case study called AgenCom - an intent-driven link decision agent.", "result": "The paper presents AgenCom as a case study demonstrating how LLM-based agents can adaptively construct communication links under diverse user preferences and channel conditions, translating natural-language intents into executable control and configuration decisions.", "conclusion": "LLM-based agentic AI provides a promising foundation for intent-aware network agents in 6G systems, offering advantages over rule-driven or centrally optimized designs by integrating heterogeneous information and enabling autonomous adaptation to dynamic user requirements and environmental conditions."}}
{"id": "2602.17106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17106", "abs": "https://arxiv.org/abs/2602.17106", "authors": ["Xiaoran Cai", "Wang Yang", "Xiyu Ren", "Chekun Law", "Rohit Sharma", "Peng Qi"], "title": "Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction", "comment": null, "summary": "Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluating sustainability rating methodologies. The framework comprises two complementary parts: STRIDE (Sustainability Trust Rating & Integrity Data Equation) provides principled criteria and a scoring system that guide the construction of firm-level benchmark datasets using large language models (LLMs), and SR-Delta, a discrepancy-analysis procedural framework that surfaces insights for potential adjustments. The framework enables scalable and comparable assessment of sustainability rating methodologies. We call on the broader AI community to adopt AI-powered approaches to strengthen and advance sustainability rating methodologies that support and enforce urgent sustainability agendas.", "AI": {"tldr": "Proposes a universal human-AI collaboration framework (STRIDE + SR-Delta) to create benchmark datasets for evaluating sustainability rating methodologies, addressing the problem of inconsistent ESG ratings across agencies.", "motivation": "Sustainability/ESG ratings from different agencies show wide variation for the same company, limiting comparability, credibility, and decision-making relevance. This inconsistency undermines the effectiveness of sustainability assessments.", "method": "Two-part framework: 1) STRIDE provides principled criteria and scoring system for constructing firm-level benchmark datasets using LLMs; 2) SR-Delta is a discrepancy-analysis procedural framework that surfaces insights for potential adjustments. The framework enables human-AI collaboration for scalable benchmark creation.", "result": "The framework enables scalable and comparable assessment of sustainability rating methodologies by generating trustworthy benchmark datasets. It provides a systematic approach to evaluate and potentially harmonize different rating methodologies.", "conclusion": "The proposed human-AI collaboration framework addresses ESG rating inconsistency by creating benchmark datasets for methodology evaluation. The authors call for broader AI community adoption of AI-powered approaches to strengthen sustainability rating methodologies and support urgent sustainability agendas."}}
{"id": "2602.17107", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17107", "abs": "https://arxiv.org/abs/2602.17107", "authors": ["Xiangyu Zhou", "Chenhan Xiao", "Yang Weng"], "title": "Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)", "comment": null, "summary": "Shapley value-based methods have become foundational in explainable artificial intelligence (XAI), offering theoretically grounded feature attributions through cooperative game theory. However, in practice, particularly in vision tasks, the assumption of feature independence breaks down, as features (i.e., pixels) often exhibit strong spatial and semantic dependencies. To address this, modern SHAP implementations now include the Owen value, a hierarchical generalization of the Shapley value that supports group attributions. While the Owen value preserves the foundations of Shapley values, its effectiveness critically depends on how feature groups are defined. We show that commonly used segmentations (e.g., axis-aligned or SLIC) violate key consistency properties, and propose a new segmentation approach that satisfies the $T$-property to ensure semantic alignment across hierarchy levels. This hierarchy enables computational pruning while improving attribution accuracy and interpretability. Experiments on image and tabular datasets demonstrate that O-Shap outperforms baseline SHAP variants in attribution precision, semantic coherence, and runtime efficiency, especially when structure matters.", "AI": {"tldr": "O-Shap introduces a new segmentation approach for Owen value-based feature attribution that satisfies the T-property, improving semantic alignment and outperforming baseline SHAP variants in accuracy, coherence, and efficiency.", "motivation": "Standard Shapley value methods assume feature independence, which breaks down in vision tasks where pixels have spatial and semantic dependencies. While Owen value (hierarchical Shapley) addresses this through group attributions, existing segmentation methods violate consistency properties and lack semantic alignment across hierarchy levels.", "method": "Proposes a new segmentation approach that satisfies the T-property to ensure semantic alignment across hierarchy levels. This enables computational pruning while maintaining attribution accuracy. The method is applied to both image and tabular datasets.", "result": "O-Shap outperforms baseline SHAP variants in attribution precision, semantic coherence, and runtime efficiency, particularly when structure matters. Experiments demonstrate improved performance on both image and tabular datasets.", "conclusion": "The proposed segmentation approach for Owen value-based attribution addresses limitations of existing methods by ensuring semantic alignment through the T-property, resulting in more accurate, interpretable, and efficient feature attributions for structured data."}}
{"id": "2602.17111", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17111", "abs": "https://arxiv.org/abs/2602.17111", "authors": ["Abdulrahman AlRabah", "Priyanka Kargupta", "Jiawei Han", "Abdussalam Alawini"], "title": "Instructor-Aligned Knowledge Graphs for Personalized Learning", "comment": null, "summary": "Mastering educational concepts requires understanding both their prerequisites (e.g., recursion before merge sort) and sub-concepts (e.g., merge sort as part of sorting algorithms). Capturing these dependencies is critical for identifying students' knowledge gaps and enabling targeted intervention for personalized learning. This is especially challenging in large-scale courses, where instructors cannot feasibly diagnose individual misunderstanding or determine which concepts need reinforcement. While knowledge graphs offer a natural representation for capturing these conceptual relationships at scale, existing approaches are either surface-level (focusing on course-level concepts like \"Algorithms\" or logistical relationships such as course enrollment), or disregard the rich pedagogical signals embedded in instructional materials. We propose InstructKG, a framework for automatically constructing instructor-aligned knowledge graphs that capture a course's intended learning progression. Given a course's lecture materials (slides, notes, etc.), InstructKG extracts significant concepts as nodes and infers learning dependencies as directed edges (e.g., \"part-of\" or \"depends-on\" relationships). The framework synergizes the rich temporal and semantic signals unique to educational materials (e.g., \"recursion\" is taught before \"mergesort\"; \"recursion\" is mentioned in the definition of \"merge sort\") with the generalizability of large language models. Through experiments on real-world, diverse lecture materials across multiple courses and human-based evaluation, we demonstrate that InstructKG captures rich, instructor-aligned learning progressions.", "AI": {"tldr": "InstructKG automatically constructs instructor-aligned knowledge graphs from lecture materials to capture learning dependencies and conceptual relationships for personalized education.", "motivation": "Understanding conceptual dependencies (prerequisites and sub-concepts) is crucial for identifying student knowledge gaps and enabling personalized interventions, especially in large-scale courses where manual diagnosis is infeasible. Existing approaches are either too surface-level or ignore pedagogical signals in instructional materials.", "method": "InstructKG extracts significant concepts as nodes and infers learning dependencies as directed edges (e.g., \"part-of\" or \"depends-on\" relationships) from lecture materials (slides, notes). It synergizes temporal and semantic signals from educational materials (teaching order, definitional mentions) with the generalizability of large language models.", "result": "Through experiments on real-world, diverse lecture materials across multiple courses and human-based evaluation, InstructKG demonstrates the ability to capture rich, instructor-aligned learning progressions.", "conclusion": "InstructKG provides an effective framework for automatically constructing knowledge graphs that capture intended learning progressions from educational materials, addressing the challenge of scalable personalized learning support in large courses."}}
{"id": "2602.17116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17116", "abs": "https://arxiv.org/abs/2602.17116", "authors": ["Ilya Levin"], "title": "Epistemology of Generative AI: The Geometry of Knowing", "comment": "27", "summary": "Generative AI presents an unprecedented challenge to our understanding of knowledge and its production. Unlike previous technological transformations, where engineering understanding preceded or accompanied deployment, generative AI operates through mechanisms whose epistemic character remains obscure, and without such understanding, its responsible integration into science, education, and institutional life cannot proceed on a principled basis. This paper argues that the missing account must begin with a paradigmatic break that has not yet received adequate philosophical attention. In the Turing-Shannon-von Neumann tradition, information enters the machine as encoded binary vectors, and semantics remains external to the process. Neural network architectures rupture this regime: symbolic input is instantly projected into a high-dimensional space where coordinates correspond to semantic parameters, transforming binary code into a position in a geometric space of meanings. It is this space that constitutes the active epistemic condition shaping generative production. Drawing on four structural properties of high-dimensional geometry concentration of measure, near-orthogonality, exponential directional capacity, and manifold regularity the paper develops an Indexical Epistemology of High-Dimensional Spaces. Building on Peirce semiotics and Papert constructionism, it reconceptualizes generative models as navigators of learned manifolds and proposes navigational knowledge as a third mode of knowledge production, distinct from both symbolic reasoning and statistical recombination.", "AI": {"tldr": "The paper argues that generative AI requires a new epistemological framework based on high-dimensional geometry, proposing \"navigational knowledge\" as a third mode of knowledge production distinct from symbolic reasoning and statistical recombination.", "motivation": "Generative AI operates through opaque mechanisms that lack proper epistemic understanding, making responsible integration into science, education, and institutions impossible without a principled foundation. Current information theory frameworks (Turing-Shannon-von Neumann) treat semantics as external to computational processes, which fails to capture how neural networks project symbolic input into semantic parameter spaces.", "method": "The paper develops an \"Indexical Epistemology of High-Dimensional Spaces\" by analyzing four structural properties of high-dimensional geometry: concentration of measure, near-orthogonality, exponential directional capacity, and manifold regularity. It builds on Peirce's semiotics and Papert's constructionism to reconceptualize generative models as navigators of learned manifolds.", "result": "The analysis reveals that neural network architectures rupture the traditional symbolic regime by instantly projecting input into high-dimensional semantic spaces where coordinates correspond to semantic parameters. This geometric space constitutes the active epistemic condition shaping generative production.", "conclusion": "The paper proposes \"navigational knowledge\" as a third mode of knowledge production, distinct from both symbolic reasoning and statistical recombination. This new epistemological framework is necessary for understanding and responsibly integrating generative AI into various domains, requiring a paradigmatic break from traditional computational models."}}
{"id": "2602.17130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17130", "abs": "https://arxiv.org/abs/2602.17130", "authors": ["Victor Kondratiev", "Irina Gribanova", "Alexander Semenov"], "title": "Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances", "comment": null, "summary": "We propose a novel parallel algorithm for decomposing hard CircuitSAT instances. The technique employs specialized constraints to partition an original SAT instance into a family of weakened formulas. Our approach is implemented as a parameterized parallel algorithm, where adjusting the parameters allows efficient identification of high-quality decompositions, guided by hardness estimations computed in parallel. We demonstrate the algorithm's practical efficacy on challenging CircuitSAT instances, including those encoding Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions.", "AI": {"tldr": "Novel parallel algorithm for decomposing hard CircuitSAT instances using specialized constraints to partition SAT instances into weakened formulas, with parameterized parallel decomposition guided by hardness estimations.", "motivation": "Hard CircuitSAT instances (like those from Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions) are computationally challenging to solve directly, requiring decomposition techniques to make them more tractable.", "method": "Parallel algorithm using specialized constraints to partition original SAT instances into families of weakened formulas; parameterized approach allows efficient identification of high-quality decompositions guided by parallel hardness estimations.", "result": "Demonstrated practical efficacy on challenging CircuitSAT instances, including Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions.", "conclusion": "The proposed parallel decomposition algorithm effectively handles hard CircuitSAT instances through constraint-based partitioning and parameterized parallel decomposition with hardness-guided optimization."}}
{"id": "2602.17145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17145", "abs": "https://arxiv.org/abs/2602.17145", "authors": ["Joseph Bingham", "Sam Helmich"], "title": "Bonsai: A Framework for Convolutional Neural Network Acceleration Using Criterion-Based Pruning", "comment": "16 pages, 4 figures, accepted to MLDM 2021", "summary": "As the need for more accurate and powerful Convolutional Neural Networks (CNNs) increases, so too does the size, execution time, memory footprint, and power consumption. To overcome this, solutions such as pruning have been proposed with their own metrics and methodologies, or criteria, for how weights should be removed. These solutions do not share a common implementation and are difficult to implement and compare. In this work, we introduce Combine, a criterion- based pruning solution and demonstrate that it is fast and effective framework for iterative pruning, demonstrate that criterion have differing effects on different models, create a standard language for comparing criterion functions, and propose a few novel criterion functions. We show the capacity of these criterion functions and the framework on VGG inspired models, pruning up to 79\\% of filters while retaining or improving accuracy, and reducing the computations needed by the network by up to 68\\%.", "AI": {"tldr": "Combine is a criterion-based pruning framework for CNNs that provides a standardized approach for comparing pruning criteria, demonstrates varying effects of different criteria across models, and achieves up to 79% filter pruning while maintaining or improving accuracy.", "motivation": "As CNNs grow larger for improved accuracy, they face increasing problems with size, execution time, memory footprint, and power consumption. Existing pruning solutions lack common implementation standards, making them difficult to implement, compare, and evaluate consistently.", "method": "Introduces Combine, a criterion-based pruning framework that provides a standardized language for comparing pruning criteria functions. The framework supports iterative pruning and includes novel criterion functions for determining which weights/filters to remove from neural networks.", "result": "The framework demonstrates varying effects of different pruning criteria across different models. On VGG-inspired models, it achieves up to 79% filter pruning while retaining or improving accuracy, and reduces computational requirements by up to 68%.", "conclusion": "Combine provides an effective, fast framework for iterative pruning with standardized criteria comparison, enabling systematic evaluation of pruning approaches and achieving significant model compression while maintaining performance."}}
{"id": "2602.17162", "categories": ["cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2602.17162", "abs": "https://arxiv.org/abs/2602.17162", "authors": ["Ariel Larey", "Elay Dahan", "Amit Bleiweiss", "Raizy Kellerman", "Guy Leib", "Omri Nayshool", "Dan Ofer", "Tal Zinger", "Dan Dominissini", "Gideon Rechavi", "Nicole Bussola", "Simon Lee", "Shane O'Connell", "Dung Hoang", "Marissa Wirth", "Alexander W. Charney", "Nati Daniel", "Yoli Shavit"], "title": "JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures", "comment": null, "summary": "Genomic Foundation Models (GFMs) have largely relied on Masked Language Modeling (MLM) or Next Token Prediction (NTP) to learn the language of life. While these paradigms excel at capturing local genomic syntax and fine-grained motif patterns, they often fail to capture the broader functional context, resulting in representations that lack a global biological perspective. We introduce JEPA-DNA, a novel pre-training framework that integrates the Joint-Embedding Predictive Architecture (JEPA) with traditional generative objectives. JEPA-DNA introduces latent grounding by coupling token-level recovery with a predictive objective in the latent space by supervising a CLS token. This forces the model to predict the high-level functional embeddings of masked genomic segments rather than focusing solely on individual nucleotides. JEPA-DNA extends both NTP and MLM paradigms and can be deployed either as a standalone from-scratch objective or as a continual pre-training enhancement for existing GFMs. Our evaluations across a diverse suite of genomic benchmarks demonstrate that JEPA-DNA consistently yields superior performance in supervised and zero-shot tasks compared to generative-only baselines. By providing a more robust and biologically grounded representation, JEPA-DNA offers a scalable path toward foundation models that understand not only the genomic alphabet, but also the underlying functional logic of the sequence.", "AI": {"tldr": "JEPA-DNA is a novel genomic foundation model framework that integrates Joint-Embedding Predictive Architecture with traditional generative objectives to capture both local genomic syntax and global functional context, outperforming existing methods on various benchmarks.", "motivation": "Current Genomic Foundation Models (GFMs) relying on Masked Language Modeling (MLM) or Next Token Prediction (NTP) excel at capturing local genomic syntax and fine-grained motif patterns but fail to capture broader functional context, resulting in representations lacking a global biological perspective.", "method": "JEPA-DNA integrates Joint-Embedding Predictive Architecture (JEPA) with traditional generative objectives, introducing latent grounding by coupling token-level recovery with predictive objectives in latent space through CLS token supervision. This forces the model to predict high-level functional embeddings of masked genomic segments rather than focusing solely on individual nucleotides. The framework extends both NTP and MLM paradigms and can be deployed as standalone from-scratch objective or continual pre-training enhancement for existing GFMs.", "result": "Evaluations across diverse genomic benchmarks demonstrate that JEPA-DNA consistently yields superior performance in supervised and zero-shot tasks compared to generative-only baselines.", "conclusion": "JEPA-DNA provides more robust and biologically grounded representations, offering a scalable path toward foundation models that understand not only the genomic alphabet but also the underlying functional logic of sequences."}}
{"id": "2602.17189", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17189", "abs": "https://arxiv.org/abs/2602.17189", "authors": ["Sicheng Mao"], "title": "Texo: Formula Recognition within 20M Parameters", "comment": null, "summary": "In this paper we present Texo, a minimalist yet highperformance formula recognition model that contains only 20 million parameters. By attentive design, distillation and transfer of the vocabulary and the tokenizer, Texo achieves comparable performance to state-of-the-art models such as UniMERNet-T and PPFormulaNet-S, while reducing the model size by 80% and 65%, respectively. This enables real-time inference on consumer-grade hardware and even in-browser deployment. We also developed a web application to demonstrate the model capabilities and facilitate its usage for end users.", "AI": {"tldr": "Texo is a lightweight formula recognition model with only 20M parameters that achieves SOTA performance while being 65-80% smaller than comparable models, enabling real-time inference on consumer hardware.", "motivation": "To create a high-performance formula recognition model that is significantly smaller than existing SOTA models, enabling practical deployment on consumer-grade hardware and in-browser applications.", "method": "Uses attentive design, distillation techniques, and transfer of vocabulary and tokenizer to create a minimalist architecture with only 20 million parameters while maintaining performance.", "result": "Achieves comparable performance to UniMERNet-T and PPFormulaNet-S while reducing model size by 80% and 65% respectively, enabling real-time inference on consumer hardware and in-browser deployment.", "conclusion": "Texo demonstrates that efficient formula recognition models can achieve SOTA performance with dramatically reduced parameter counts, making them practical for real-world deployment scenarios including web applications."}}
{"id": "2602.17217", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17217", "abs": "https://arxiv.org/abs/2602.17217", "authors": ["Enrique Crespo-Fernandez", "Oliver Ray", "Telmo de Menezes e Silva Filho", "Peter Flach"], "title": "Continual learning and refinement of causal models through dynamic predicate invention", "comment": null, "summary": "Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world models entirely online by integrating continuous model learning and repair into the agent's decision loop, by leveraging the power of Meta-Interpretive Learning and predicate invention to find semantically meaningful and reusable abstractions, allowing an agent to construct a hierarchy of disentangled, high-quality concepts from its observations. We demonstrate that our lifted inference approach scales to domains with complex relational dynamics, where propositional methods suffer from combinatorial explosion, while achieving sample-efficiency orders of magnitude higher than the established PPO neural-network-based baseline.", "AI": {"tldr": "A framework for online symbolic causal world model construction using Meta-Interpretive Learning and predicate invention to achieve sample efficiency and scalability in complex relational domains.", "motivation": "Standard world modelling methods suffer from sample inefficiency, lack of transparency, and poor scalability, making them inadequate for agents needing to internalize complex environmental logic.", "method": "Integrates continuous model learning and repair into decision loop using Meta-Interpretive Learning and predicate invention to construct symbolic causal world models online, enabling lifted inference for relational dynamics.", "result": "Achieves orders of magnitude higher sample efficiency than PPO neural-network baseline and scales to complex relational domains where propositional methods suffer combinatorial explosion.", "conclusion": "The framework successfully constructs hierarchical, disentangled, high-quality concepts from observations, providing transparent and scalable symbolic causal world models for efficient navigation in complex environments."}}
{"id": "2602.17221", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.17221", "abs": "https://arxiv.org/abs/2602.17221", "authors": ["Yi-Chih Huang"], "title": "From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences", "comment": "also in Chinese", "summary": "Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.\n  This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).\n  This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.", "AI": {"tldr": "This paper proposes and validates an AI Agent-based collaborative workflow for humanities and social sciences research, using Taiwan's Claude.ai usage data as an empirical case study to demonstrate the methodology's feasibility and identify three human-AI collaboration modes.", "motivation": "Current generative AI research focuses primarily on software engineering and natural sciences, with limited methodological exploration for humanities and social sciences, creating a gap that needs to be addressed for these disciplines.", "method": "The study proposes a seven-stage modular workflow based on three principles (task modularization, human-AI division of labor, and verifiability), validated using Taiwan's Claude.ai usage data from the Anthropic Economic Index (N=7,729 conversations) as an empirical demonstration.", "result": "The study successfully demonstrates the workflow's feasibility and identifies three operational modes of human-AI collaboration: direct execution, iterative refinement, and human-led, while revealing the irreplaceability of human judgment in research formulation, theoretical interpretation, contextual reasoning, and ethical reflection.", "conclusion": "The paper contributes a replicable AI collaboration framework for humanities and social sciences research, establishes a taxonomy of human-AI collaboration modes, and acknowledges limitations including single-platform data, cross-sectional design, and AI reliability risks."}}
{"id": "2602.17222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17222", "abs": "https://arxiv.org/abs/2602.17222", "authors": ["Ben Yellin", "Ehud Ezra", "Mark Foreman", "Shula Grinapol"], "title": "Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight", "comment": null, "summary": "Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate prediction depends on complex interactions between psychological traits and situational constraints. Prompting-based approaches can be brittle in this setting, exhibiting identity drift and limited ability to leverage increasingly detailed persona descriptions. To address these limitations, we introduce the Large Behavioral Model (LBM), a behavioral foundation model fine-tuned to predict individual strategic choices with high fidelity. LBM shifts from transient persona prompting to behavioral embedding by conditioning on a structured, high-dimensional trait profile derived from a comprehensive psychometric battery. Trained on a proprietary dataset linking stable dispositions, motivational states, and situational constraints to observed choices, LBM learns to map rich psychological profiles to discrete actions across diverse strategic dilemmas. In a held-out scenario evaluation, LBM fine-tuning improves behavioral prediction relative to the unadapted Llama-3.1-8B-Instruct backbone and performs comparably to frontier baselines when conditioned on Big Five traits. Moreover, we find that while prompting-based baselines exhibit a complexity ceiling, LBM continues to benefit from increasingly dense trait profiles, with performance improving as additional trait dimensions are provided. Together, these results establish LBM as a scalable approach for high-fidelity behavioral simulation, enabling applications in strategic foresight, negotiation analysis, cognitive security, and decision support.", "AI": {"tldr": "The paper introduces LBM (Large Behavioral Model), a behavioral foundation model fine-tuned to predict individual strategic choices by conditioning on structured trait profiles instead of using brittle prompting approaches.", "motivation": "LLMs struggle to generate consistent, individual-specific behavior in high-stakes decision-making, especially when predictions depend on complex interactions between psychological traits and situational constraints. Prompting approaches suffer from identity drift and limited ability to leverage detailed persona descriptions.", "method": "LBM shifts from transient persona prompting to behavioral embedding by conditioning on structured, high-dimensional trait profiles derived from comprehensive psychometric batteries. The model is fine-tuned on a proprietary dataset linking stable dispositions, motivational states, and situational constraints to observed choices, learning to map rich psychological profiles to discrete actions across diverse strategic dilemmas.", "result": "LBM fine-tuning improves behavioral prediction relative to the unadapted Llama-3.1-8B-Instruct backbone and performs comparably to frontier baselines when conditioned on Big Five traits. While prompting-based baselines exhibit a complexity ceiling, LBM continues to benefit from increasingly dense trait profiles, with performance improving as additional trait dimensions are provided.", "conclusion": "LBM establishes a scalable approach for high-fidelity behavioral simulation, enabling applications in strategic foresight, negotiation analysis, cognitive security, and decision support by overcoming the limitations of prompting-based methods for predicting individual decision-making."}}
{"id": "2602.17229", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17229", "abs": "https://arxiv.org/abs/2602.17229", "authors": ["Bianca Raimondi", "Maurizio Gabbrielli"], "title": "Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy", "comment": "Preprint. Under review", "summary": "The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional activation vectors from different LLMs, we probe whether different cognitive levels, ranging from basic recall (Remember) to abstract synthesis (Create), are linearly separable within the model's residual streams. Our results demonstrate that linear classifiers achieve approximately 95% mean accuracy across all Bloom levels, providing strong evidence that cognitive level is encoded in a linearly accessible subspace of the model's representations. These findings provide evidence that the model resolves the cognitive difficulty of a prompt early in the forward pass, with representations becoming increasingly separable across layers.", "AI": {"tldr": "LLMs encode cognitive complexity levels from Bloom's Taxonomy in linearly separable neural representations, with ~95% classification accuracy showing early resolution of cognitive difficulty.", "motivation": "The black-box nature of LLMs requires new evaluation frameworks beyond surface-level metrics to understand how they internally represent cognitive complexity.", "method": "Analyzed high-dimensional activation vectors from different LLMs using Bloom's Taxonomy as a hierarchical lens, probing whether different cognitive levels (Remember to Create) are linearly separable in residual streams.", "result": "Linear classifiers achieved approximately 95% mean accuracy across all Bloom levels, showing cognitive level is encoded in linearly accessible subspaces. Representations become increasingly separable across layers, with cognitive difficulty resolved early in forward pass.", "conclusion": "LLMs internally represent cognitive complexity in linearly separable neural representations, providing evidence for structured encoding of cognitive difficulty that emerges early in processing."}}
{"id": "2602.17234", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17234", "abs": "https://arxiv.org/abs/2602.17234", "authors": ["Zeyu Zhang", "Ryan Chen", "Bradly C. Stadie"], "title": "All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting", "comment": "8 pages plus appendix", "summary": "To evaluate whether LLMs can accurately predict future events, we need the ability to \\textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded during training, undermining the validity of retrospective evaluation. We introduce a claim-level framework for detecting and quantifying this \\emph{temporal knowledge leakage}. Our approach decomposes model rationales into atomic claims and categorizes them by temporal verifiability, then applies \\textit{Shapley values} to measure each claim's contribution to the prediction. This yields the \\textbf{Shapley}-weighted \\textbf{D}ecision-\\textbf{C}ritical \\textbf{L}eakage \\textbf{R}ate (\\textbf{Shapley-DCLR}), an interpretable metric that captures what fraction of decision-driving reasoning derives from leaked information. Building on this framework, we propose \\textbf{Time}-\\textbf{S}upervised \\textbf{P}rediction with \\textbf{E}xtracted \\textbf{C}laims (\\textbf{TimeSPEC}), which interleaves generation with claim verification and regeneration to proactively filter temporal contamination -- producing predictions where every supporting claim can be traced to sources available before the cutoff date. Experiments on 350 instances spanning U.S. Supreme Court case prediction, NBA salary estimation, and stock return ranking reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, demonstrating that explicit, interpretable claim-level verification outperforms prompt-based temporal constraints for reliable backtesting.", "AI": {"tldr": "The paper introduces a framework for detecting temporal knowledge leakage in LLMs during backtesting and proposes TimeSPEC, a method that verifies claims against pre-cutoff sources to produce temporally valid predictions.", "motivation": "LLMs may inadvertently use post-cutoff knowledge encoded during training when making predictions about past events, undermining the validity of retrospective evaluation (backtesting). Current methods lack interpretable ways to detect and quantify this temporal knowledge leakage.", "method": "1) Introduces a claim-level framework that decomposes model rationales into atomic claims and categorizes them by temporal verifiability. 2) Uses Shapley values to measure each claim's contribution to predictions, yielding Shapley-DCLR metric. 3) Proposes TimeSPEC (Time-Supervised Prediction with Extracted Claims) which interleaves generation with claim verification and regeneration to filter temporal contamination.", "result": "Experiments on 350 instances across three domains (U.S. Supreme Court case prediction, NBA salary estimation, stock return ranking) reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, outperforming prompt-based temporal constraints.", "conclusion": "Explicit, interpretable claim-level verification through TimeSPEC is more effective than prompt-based temporal constraints for reliable backtesting of LLMs, providing a framework to detect and mitigate temporal knowledge leakage."}}
{"id": "2602.17245", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17245", "abs": "https://arxiv.org/abs/2602.17245", "authors": ["Linxi Jiang", "Rui Xi", "Zhijie Liu", "Shuo Chen", "Zhiqiang Lin", "Suman Nath"], "title": "Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web", "comment": null, "summary": "The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level primitives such as clicks and keystrokes. These operations are brittle, inefficient, and difficult to verify. Complementing content-oriented efforts such as NLWeb's semantic layer for retrieval, we argue that the agentic web also requires a semantic layer for web actions. We propose \\textbf{Web Verbs}, a web-scale set of typed, semantically documented functions that expose site capabilities through a uniform interface, whether implemented through APIs or robust client-side workflows. These verbs serve as stable and composable units that agents can discover, select, and synthesize into concise programs. This abstraction unifies API-based and browser-based paradigms, enabling LLMs to synthesize reliable and auditable workflows with explicit control and data flow. Verbs can carry preconditions, postconditions, policy tags, and logging support, which improves \\textbf{reliability} by providing stable interfaces, \\textbf{efficiency} by reducing dozens of steps into a few function calls, and \\textbf{verifiability} through typed contracts and checkable traces. We present our vision, a proof-of-concept implementation, and representative case studies that demonstrate concise and robust execution compared to existing agents. Finally, we outline a roadmap for standardization to make verbs deployable and trustworthy at web scale.", "AI": {"tldr": "Web Verbs: A semantic layer for web actions that provides typed, documented functions exposing site capabilities through uniform interfaces, enabling LLMs to synthesize reliable, efficient, and verifiable workflows.", "motivation": "The web is evolving from human browsing to agentic environments where software agents act on behalf of users. Current web agents operate on low-level primitives (clicks, keystrokes) that are brittle, inefficient, and difficult to verify, creating a need for higher-level semantic abstractions for web actions.", "method": "Proposes Web Verbs - a web-scale set of typed, semantically documented functions that expose site capabilities through a uniform interface, whether implemented through APIs or robust client-side workflows. These verbs serve as stable, composable units with preconditions, postconditions, policy tags, and logging support.", "result": "Web Verbs improve reliability by providing stable interfaces, efficiency by reducing dozens of steps into few function calls, and verifiability through typed contracts and checkable traces. A proof-of-concept implementation and case studies demonstrate concise and robust execution compared to existing agents.", "conclusion": "Web Verbs provide a semantic layer for web actions that unifies API-based and browser-based paradigms, enabling LLMs to synthesize reliable and auditable workflows. The approach addresses key challenges in agentic web environments and outlines a roadmap for standardization to achieve web-scale deployability and trustworthiness."}}
{"id": "2602.17288", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17288", "abs": "https://arxiv.org/abs/2602.17288", "authors": ["Anuj Gupta"], "title": "ArXiv-to-Model: A Practical Study of Scientific LM Training", "comment": "15 pages, 6 figures, 1 table", "summary": "While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.", "AI": {"tldr": "Training a 1.36B-parameter scientific language model from raw arXiv LaTeX sources using constrained compute (2xA100 GPUs), with detailed analysis of preprocessing, tokenization, and infrastructure bottlenecks.", "motivation": "Despite strong reasoning capabilities in frontier LLMs, there's limited documentation on practical training of domain-specialized scientific language models from raw sources. The work aims to provide transparent guidance for researchers with moderate compute budgets.", "method": "End-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training. Conducted 24 experimental runs analyzing training stability, scaling behavior, and infrastructure bottlenecks.", "result": "Preprocessing decisions significantly affect usable token volume; tokenization impacts symbolic stability; storage and I/O constraints can rival compute as limiting factors. Showed stable training behavior with 52B pretraining tokens.", "conclusion": "Provides engineering-grounded, transparent account of training small scientific language models from scratch, offering insights for researchers with constrained compute seeking to build domain-specialized models."}}
{"id": "2602.17308", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17308", "abs": "https://arxiv.org/abs/2602.17308", "authors": ["Hui Min Wong", "Philip Heesen", "Pascal Janetzky", "Martin Bendszus", "Stefan Feuerriegel"], "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions", "comment": null, "summary": "Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that demand immediate intervention. Yet, the ability of medical LLMs to generate informative follow-up questions and thus reason over differential diagnoses remains underexplored. Here, we introduce MedClarify, an AI agent for information-seeking that can generate follow-up questions for iterative reasoning to support diagnostic decision-making. Specifically, MedClarify computes a list of candidate diagnoses analogous to a differential diagnosis, and then proactively generates follow-up questions aimed at reducing diagnostic uncertainty. By selecting the question with the highest expected information gain, MedClarify enables targeted, uncertainty-aware reasoning to improve diagnostic performance. In our experiments, we first demonstrate the limitations of current LLMs in medical reasoning, which often yield multiple, similarly likely diagnoses, especially when patient cases are incomplete or relevant information for diagnosis is missing. We then show that our information-theoretic reasoning approach can generate effective follow-up questioning and thereby reduces diagnostic errors by ~27 percentage points (p.p.) compared to a standard single-shot LLM baseline. Altogether, MedClarify offers a path to improve medical LLMs through agentic information-seeking and to thus promote effective dialogues with medical LLMs that reflect the iterative and uncertain nature of real-world clinical reasoning.", "AI": {"tldr": "MedClarify is an AI agent that generates follow-up questions for medical diagnosis by computing differential diagnoses and selecting questions with highest information gain, reducing diagnostic errors by ~27% compared to single-shot LLMs.", "motivation": "Current medical LLMs lack the ability to engage in iterative reasoning through follow-up questioning, which is essential for clinical diagnosis where initial presentations are often incomplete and require systematic history-taking to resolve uncertainty and exclude emergencies.", "method": "MedClarify computes a list of candidate diagnoses (differential diagnosis), then proactively generates follow-up questions aimed at reducing diagnostic uncertainty by selecting questions with the highest expected information gain using an information-theoretic reasoning approach.", "result": "The approach reduces diagnostic errors by approximately 27 percentage points compared to standard single-shot LLM baselines, demonstrating that targeted, uncertainty-aware reasoning through follow-up questioning significantly improves diagnostic performance.", "conclusion": "MedClarify offers a path to improve medical LLMs through agentic information-seeking, promoting effective dialogues that reflect the iterative and uncertain nature of real-world clinical reasoning."}}
{"id": "2602.17385", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17385", "abs": "https://arxiv.org/abs/2602.17385", "authors": ["Angelo Porrello", "Pietro Buzzega", "Felix Dangel", "Thomas Sommariva", "Riccardo Salami", "Lorenzo Bonicelli", "Simone Calderara"], "title": "Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature", "comment": "Accepted to ICLR 2026", "summary": "Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; however, existing approaches typically require external task data, conflicting with modularity and data availability constraints (e.g., privacy requirements). We propose a dataless approach by framing regularization against representation drift as a curvature matrix approximation problem. This allows us to leverage well-established techniques; in particular, we adopt Kronecker-Factored Approximate Curvature and obtain a practical regularizer that achieves state-of-the-art results in task addition and negation. Our method has constant complexity in the number of tasks and promotes robustness to task vector rescaling, eliminating the need for held-out tuning.", "AI": {"tldr": "Proposes a dataless regularization method using curvature matrix approximation to prevent representation drift in task arithmetic, achieving SOTA results without external task data.", "motivation": "Task arithmetic suffers from cross-task interference causing representation drift and performance degradation. Existing regularization approaches require external task data, conflicting with modularity and privacy constraints.", "method": "Frames regularization against representation drift as a curvature matrix approximation problem, leveraging Kronecker-Factored Approximate Curvature (KFAC) to create a practical dataless regularizer.", "result": "Achieves state-of-the-art results in task addition and negation, with constant complexity in number of tasks, robustness to task vector rescaling, and eliminates need for held-out tuning.", "conclusion": "The proposed dataless regularization approach effectively addresses representation drift in task arithmetic while maintaining modularity and addressing data availability constraints."}}
{"id": "2602.17386", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17386", "abs": "https://arxiv.org/abs/2602.17386", "authors": ["Adri\u00e0 Molina", "Oriol Ramos Terrades", "Josep Llad\u00f3s"], "title": "Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval", "comment": "Submitted for ICPR Review", "summary": "Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.", "AI": {"tldr": "A novel framework integrating formal verification with deep learning for image retrieval, enabling trustworthy, verifiable results for complex natural language queries through graph-based verification and neural code generation.", "motivation": "Current embedding-based models struggle with complex queries involving relationships, object compositions, and precise constraints (identities, counts, proportions), resulting in unreliable or unresolved results. There's a need for trustworthy, verifiable retrieval that moves beyond the ambiguity of vector representations.", "method": "Integration of formal verification into deep learning-based image retrieval using graph-based verification methods and neural code generation. The framework explicitly verifies each atomic truth in user queries against retrieved content, grounding results in formal reasoning rather than vector approximations.", "result": "The framework supports open-vocabulary natural language queries while producing trustworthy, verifiable results. It identifies and marks which specific constraints are satisfied and which remain unmet, offering transparent and accountable retrieval while boosting performance of popular embedding-based approaches.", "conclusion": "By combining formal verification with neural approaches, the framework addresses limitations of current retrieval systems, providing more reliable results for complex queries through explicit verification of query constraints against retrieved content."}}
{"id": "2602.17402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17402", "abs": "https://arxiv.org/abs/2602.17402", "authors": ["Michele Zanitti", "Vanja Miskovic", "Francesco Trov\u00f2", "Alessandra Laura Giulia Pedrocchi", "Ming Shen", "Yan Kyaw Tun", "Arsela Prelaj", "Sokol Kosta"], "title": "A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities", "comment": "Accepted at The 13th IEEE International Conference on Big Data (IEEE BigData 2025)", "summary": "Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's condition at diagnosis. However, real-world clinical datasets are often incomplete, with entire modalities missing for a significant fraction of patients. State-of-the-art models rely on available data to create patient-level representations or use generative models to infer missing modalities, but they lack robustness in cases of severe missingness. We propose a Multimodal Contrastive Variational AutoEncoder (MCVAE) to address this issue: modality-specific variational encoders capture the uncertainty in each data source, and a fusion bottleneck with learned gating mechanisms is introduced to normalize the contributions from present modalities. We propose a multi-task objective that combines survival loss and reconstruction loss to regularize patient representations, along with a cross-modal contrastive loss that enforces cross-modal alignment in the latent space. During training, we apply stochastic modality masking to improve the robustness to arbitrary missingness patterns. Extensive evaluations on the TCGA-LUAD (n=475) and TCGA-LUSC (n=446) datasets demonstrate the efficacy of our approach in predicting disease-specific survival (DSS) and its robustness to severe missingness scenarios compared to two state-of-the-art models. Finally, we bring some clarifications on multimodal integration by testing our model on all subsets of modalities, finding that integration is not always beneficial to the task.", "AI": {"tldr": "MCVAE: A multimodal contrastive variational autoencoder for NSCLC survival prediction that handles missing modalities via modality-specific encoders, learned gating fusion, and stochastic masking during training.", "motivation": "Predicting NSCLC survival is challenging due to individual variability; multimodal integration (WSI, transcriptomics, methylation) offers complementary views but real-world datasets often have missing modalities, and current models lack robustness to severe missingness.", "method": "Multimodal Contrastive Variational AutoEncoder (MCVAE) with modality-specific variational encoders, fusion bottleneck with learned gating mechanisms, multi-task objective combining survival loss, reconstruction loss, and cross-modal contrastive loss, plus stochastic modality masking during training.", "result": "Extensive evaluations on TCGA-LUAD (n=475) and TCGA-LUSC (n=446) show efficacy in predicting disease-specific survival and robustness to severe missingness compared to two state-of-the-art models; analysis reveals integration is not always beneficial across all modality subsets.", "conclusion": "MCVAE effectively handles missing modalities in multimodal NSCLC survival prediction, demonstrating robustness to severe missingness while providing insights that multimodal integration doesn't always improve performance across all modality combinations."}}
{"id": "2602.17418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17418", "abs": "https://arxiv.org/abs/2602.17418", "authors": ["Diana Addae", "Diana Rogachova", "Nafiseh Kahani", "Masoud Barati", "Michael Christensen", "Chen Zhou"], "title": "A Privacy by Design Framework for Large Language Model-Based Applications for Children", "comment": null, "summary": "Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in practice. To address this challenge, this article proposes a framework based on Privacy-by-Design (PbD), which guides designers and developers to take on a proactive and risk-averse approach to technology design. Our framework includes principles from several privacy regulations, such as the General Data Protection Regulation (GDPR) from the European Union, the Personal Information Protection and Electronic Documents Act (PIPEDA) from Canada, and the Children's Online Privacy Protection Act (COPPA) from the United States. We map these principles to various stages of applications that use Large Language Models (LLMs), including data collection, model training, operational monitoring, and ongoing validation. For each stage, we discuss the operational controls found in the recent academic literature to help AI service providers and developers reduce privacy risks while meeting legal standards. In addition, the framework includes design guidelines for children, drawing from the United Nations Convention on the Rights of the Child (UNCRC), the UK's Age-Appropriate Design Code (AADC), and recent academic research. To demonstrate how this framework can be applied in practice, we present a case study of an LLM-based educational tutor for children under 13. Through our analysis and the case study, we show that by using data protection strategies such as technical and organizational controls and making age-appropriate design decisions throughout the LLM life cycle, we can support the development of AI applications for children that provide privacy protections and comply with legal requirements.", "AI": {"tldr": "Proposes a Privacy-by-Design framework integrating multiple privacy regulations and children's rights principles to guide development of AI applications for children, with LLM-based educational tutor case study.", "motivation": "Children increasingly use AI technologies, raising privacy concerns. Existing privacy regulations require protections but implementation is challenging in practice, especially for children's applications.", "method": "Develops a Privacy-by-Design framework combining principles from GDPR, PIPEDA, COPPA, UNCRC, and UK's AADC. Maps these principles to LLM lifecycle stages (data collection, model training, operational monitoring, validation) and identifies operational controls from academic literature. Includes design guidelines for children and demonstrates with LLM-based educational tutor case study.", "result": "Framework provides structured approach for AI developers to implement privacy protections throughout LLM lifecycle. Case study demonstrates practical application, showing how technical/organizational controls and age-appropriate design decisions can reduce privacy risks while meeting legal requirements.", "conclusion": "Privacy-by-Design framework enables development of AI applications for children that provide adequate privacy protections and comply with legal standards through proactive, risk-averse approach across LLM lifecycle stages."}}
{"id": "2602.17442", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17442", "abs": "https://arxiv.org/abs/2602.17442", "authors": ["Marco Avolio", "Potito Aghilar", "Sabino Roccotelli", "Vito Walter Anelli", "Chiara Mallamaci", "Vincenzo Paparella", "Marco Valentini", "Alejandro Bellog\u00edn", "Michelantonio Trizio", "Joseph Trotta", "Antonio Ferrara", "Tommaso Di Noia"], "title": "WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation", "comment": null, "summary": "Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/", "code_url": "https://github.com/sisinflab/warprec", "code_stars": 2, "code_last_update": "2026-02-19", "AI": {"tldr": "WarpRec is a high-performance recommender systems framework that bridges academia-industry gaps with backend-agnostic architecture, supporting 50+ algorithms, 40 metrics, and 19 strategies while enabling seamless local-to-distributed execution with sustainability tracking.", "motivation": "The fractured ecosystem in recommender systems research forces researchers to choose between easy in-memory experimentation and costly distributed industrial engines, creating a barrier to innovation and practical deployment.", "method": "Developed WarpRec with a novel backend-agnostic architecture that supports 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering/splitting strategies, enabling seamless transition from local execution to distributed training with integrated CodeCarbon for energy tracking.", "result": "Created a framework that eliminates the trade-off between experimental ease and industrial scalability, demonstrates that scalability doesn't require sacrificing scientific integrity or sustainability, and anticipates the shift toward Agentic AI in recommender systems.", "conclusion": "WarpRec bridges the academia-industry gap and serves as an architectural backbone for next-generation sustainable, agent-ready recommender systems, with code publicly available for community use."}}
{"id": "2602.17508", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17508", "abs": "https://arxiv.org/abs/2602.17508", "authors": ["Pranay Jain", "Maximilian Kasper", "G\u00f6ran K\u00f6ber", "Axel Plinge", "Dominik Seu\u00df"], "title": "Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems", "comment": "11 pages, 7 figures, Funding: GreenICT@FMD (BMFTR grant 16ME0491K)", "summary": "This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic approach to evaluate across key performance indicators (KPIs) and identify optimal combinations of processor and AI model. The research highlights a nearlinear correlation between floating-point operations (FLOPs) and inference time, offering a reliable metric for estimating computational demands. Using Pareto analysis, we demonstrate how to balance trade-offs between energy consumption and model accuracy, ensuring that AI applications meet performance requirements without compromising sustainability. Key findings indicate that the M7 processor is ideal for short inference cycles, while the M4 processor offers better energy efficiency for longer inference tasks. The M0+ processor, while less efficient for complex AI models, remains suitable for simpler tasks. This work provides insights for developers, guiding them to design energy-efficient AI systems that deliver high performance in realworld applications.", "AI": {"tldr": "A benchmarking framework for optimizing AI models on ARM Cortex processors (M0+, M4, M7) with focus on energy efficiency, accuracy, and resource utilization in embedded systems, revealing processor-specific optimization strategies.", "motivation": "The need for systematic evaluation of AI model performance on ARM Cortex processors in embedded systems, balancing energy efficiency, accuracy, and resource constraints for sustainable AI deployment.", "method": "Design of automated test bench for systematic evaluation across KPIs, using FLOPs as computational demand metric and Pareto analysis to balance energy consumption vs. model accuracy trade-offs.", "result": "Near-linear correlation between FLOPs and inference time; M7 ideal for short inference cycles, M4 better for energy efficiency in longer tasks, M0+ suitable for simpler models; processor-specific optimization strategies identified.", "conclusion": "Provides practical guidance for developers to design energy-efficient AI systems on ARM Cortex processors, enabling informed processor selection and optimization for real-world embedded applications."}}
{"id": "2602.17529", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17529", "abs": "https://arxiv.org/abs/2602.17529", "authors": ["Dun Yuan", "Hao Zhou", "Xue Liu", "Hao Chen", "Yan Xin", "Jianzhong", "Zhang"], "title": "Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation", "comment": null, "summary": "Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowledge graphs (KGs) with retrieval-augmented generation (RAG) to enhance LLMs for telecom-specific tasks. In particular, the KG provides a structured representation of domain knowledge derived from telecom standards and technical documents, while RAG enables dynamic retrieval of relevant facts to ground the model's outputs. Such a combination improves factual accuracy, reduces hallucination, and ensures compliance with telecom specifications.Experimental results across benchmark datasets demonstrate that KG-RAG outperforms both LLM-only and standard RAG baselines, e.g., KG-RAG achieves an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models. These results highlight KG-RAG's effectiveness in producing accurate, reliable, and explainable outputs in complex telecom scenarios.", "AI": {"tldr": "KG-RAG integrates knowledge graphs with retrieval-augmented generation to enhance LLMs for telecom tasks, reducing hallucinations and improving accuracy by 14.3% over standard RAG and 21.6% over LLM-only models.", "motivation": "General-domain LLMs struggle with telecom-specific tasks due to domain complexity, evolving standards, specialized terminology, leading to hallucinations and reduced utility in telecom operations.", "method": "KG-RAG framework combines knowledge graphs (structured representation of telecom domain knowledge from standards/technical documents) with retrieval-augmented generation (dynamic retrieval of relevant facts) to ground LLM outputs.", "result": "KG-RAG outperforms both LLM-only and standard RAG baselines, achieving average accuracy improvements of 14.3% over RAG and 21.6% over LLM-only models across benchmark datasets.", "conclusion": "KG-RAG effectively produces accurate, reliable, and explainable outputs in complex telecom scenarios by integrating structured domain knowledge with dynamic retrieval mechanisms."}}
{"id": "2602.17544", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17544", "abs": "https://arxiv.org/abs/2602.17544", "authors": ["Shashank Aggarwal", "Ram Vikas Mishra", "Amit Awekar"], "title": "Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability", "comment": null, "summary": "In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.", "AI": {"tldr": "The paper introduces two novel metrics\u2014reusability and verifiability\u2014to evaluate Chain-of-Thought reasoning quality in multi-agent IR pipelines, revealing these metrics don't correlate with standard accuracy and that specialized reasoning models don't consistently produce better CoTs than general-purpose LLMs.", "motivation": "Current evaluation of Chain-of-Thought reasoning in multi-agent IR pipelines focuses narrowly on target task accuracy, which fails to assess the quality or utility of the reasoning process itself. There's a need for better metrics to evaluate reasoning quality beyond just final answer correctness.", "method": "The authors introduce a Thinker-Executor framework that decouples CoT generation from execution. They propose two novel measures: reusability (how easily an Executor can reuse the Thinker's CoT) and verifiability (how frequently an Executor can match the Thinker's answer using the CoT). They evaluated four Thinker models against a committee of ten Executor models across five benchmarks.", "result": "The results show that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.", "conclusion": "The paper demonstrates the importance of evaluating reasoning quality beyond accuracy metrics and introduces two practical measures for assessing Chain-of-Thought reasoning. The findings challenge assumptions about specialized reasoning models and highlight the need for more comprehensive evaluation frameworks in multi-agent reasoning systems."}}
{"id": "2602.17547", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17547", "abs": "https://arxiv.org/abs/2602.17547", "authors": ["Yue Liu", "Zhiyuan Hu", "Flood Sung", "Jiaheng Zhang", "Bryan Hooi"], "title": "KLong: Training LLM Agent for Extremely Long-horizon Tasks", "comment": null, "summary": "This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.", "AI": {"tldr": "KLong is an open-source LLM agent trained for extremely long-horizon tasks using trajectory-splitting SFT and progressive RL training, achieving superior performance over larger models on research paper and coding benchmarks.", "motivation": "The need for LLM agents capable of solving extremely long-horizon tasks, particularly in research and coding domains where tasks require extended reasoning and multi-step problem-solving capabilities.", "method": "Two-phase approach: 1) Cold-start via trajectory-splitting SFT that preserves early context while progressively truncating later context with overlap between sub-trajectories; 2) Progressive RL training with multiple stages of progressively extended timeouts. Uses Research-Factory pipeline to generate high-quality training data from research papers with evaluation rubrics.", "result": "KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, with performance improvements generalizing to other coding benchmarks like SWE-bench Verified and MLE-bench.", "conclusion": "The proposed trajectory-splitting SFT and progressive RL training enable effective training of LLM agents for extremely long-horizon tasks, achieving state-of-the-art performance with smaller model sizes compared to larger competitors."}}
{"id": "2602.17560", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17560", "abs": "https://arxiv.org/abs/2602.17560", "authors": ["Hongjue Zhao", "Haosen Sun", "Jiangtao Kong", "Xiaochang Li", "Qineng Wang", "Liwei Jiang", "Qi Zhu", "Tarek Abdelzaher", "Yejin Choi", "Manling Li", "Huajie Shao"], "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment", "comment": "Accepted by ICLR 2026", "summary": "Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \\textit{(ii)} an over-reliance on \\textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \\textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \\textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \\textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \\textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\\%$ improvement over TruthfulQA, $2.5\\%$ over UltraFeedback, and $2.4\\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.", "AI": {"tldr": "ODESteer: A unified ODE-based theoretical framework for activation steering in LLM alignment that interprets conventional activation addition as first-order ODE approximation and uses barrier functions for multi-step adaptive steering.", "motivation": "Current activation steering methods lack unified theoretical framework and rely on one-step steering that fails to capture complex activation distribution patterns, limiting their effectiveness in LLM alignment.", "method": "Proposes ODE-based theoretical framework where activation steering is formulated as solving ODEs; conventional activation addition is first-order approximation; steering directions identified via barrier functions defined as log-density ratio between positive/negative activations; implements ODESteer for multi-step adaptive steering.", "result": "ODESteer achieves consistent improvements over SOTA activation steering methods: 5.7% improvement on TruthfulQA, 2.5% on UltraFeedback, and 2.4% on RealToxicityPrompts across diverse LLM alignment benchmarks.", "conclusion": "Establishes principled ODE-based theoretical foundation for activation steering in LLM alignment, validated empirically through ODESteer method that outperforms existing approaches on multiple benchmarks."}}
{"id": "2602.17566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17566", "abs": "https://arxiv.org/abs/2602.17566", "authors": ["Asif Hasan Chowdhury", "Md. Fahim Islam", "M Ragib Anjum Riad", "Faiyaz Bin Hashem", "Md Tanzim Reza", "Md. Golam Rabiul Alam"], "title": "A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN", "comment": null, "summary": "The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.", "AI": {"tldr": "A hybrid federated learning approach combining SWIN Transformer and CNN models for secure, distributed lung disease diagnosis from X-rays, focusing on COVID-19 and pneumonia detection.", "motivation": "Leverage computational advancements and AI to create secure, distributed medical diagnosis systems that protect patient data privacy while improving diagnostic accuracy for lung diseases like COVID-19 and pneumonia.", "method": "Hybrid ensemble approach combining SWIN Transformer with CNN models (DenseNet201, Inception V3, VGG19) using TensorFlow/Keras, integrated with federated learning for distributed, secure training across multiple medical institutions.", "result": "Proposed system enables accurate detection of COVID-19 and pneumonia from X-ray reports while maintaining data privacy through federated learning, providing a reliable diagnostic tool for physicians.", "conclusion": "The federated learning-based hybrid AI model improves disease diagnosis accuracy and severity prediction through real-time continual learning while ensuring data security and authenticity in medical applications."}}
{"id": "2602.17602", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17602", "abs": "https://arxiv.org/abs/2602.17602", "authors": ["Hojung Jung", "Rodrigo Hormazabal", "Jaehyeong Jo", "Youngrok Park", "Kyunggeun Roh", "Se-Young Yun", "Sehui Han", "Dae-Woong Jeong"], "title": "MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models", "comment": null, "summary": "Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.", "AI": {"tldr": "MolHIT introduces a hierarchical discrete diffusion model for molecular graph generation that achieves near-perfect chemical validity and state-of-the-art performance on MOSES benchmark.", "motivation": "Existing graph diffusion models for molecular generation suffer from low chemical validity and struggle to meet desired properties compared to 1D modeling approaches, creating a performance gap that needs to be addressed.", "method": "MolHIT uses a Hierarchical Discrete Diffusion Model that generalizes discrete diffusion to additional categories encoding chemical priors, combined with decoupled atom encoding that splits atom types according to their chemical roles.", "result": "Achieves new state-of-the-art performance on MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. Demonstrates strong performance in downstream tasks including multi-property guided generation and scaffold extension.", "conclusion": "MolHIT overcomes long-standing performance limitations in molecular graph generation, establishing graph diffusion models as competitive with 1D approaches while maintaining chemical validity."}}
{"id": "2602.17607", "categories": ["cs.AI", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.17607", "abs": "https://arxiv.org/abs/2602.17607", "authors": ["Jianda Du", "Youran Sun", "Haizhao Yang"], "title": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing", "comment": null, "summary": "PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpretability. We introduce \\texttt{AutoNumerics}, a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for general PDEs directly from natural language descriptions. Unlike black-box neural solvers, our framework generates transparent solvers grounded in classical numerical analysis. We introduce a coarse-to-fine execution strategy and a residual-based self-verification mechanism. Experiments on 24 canonical and real-world PDE problems demonstrate that \\texttt{AutoNumerics} achieves competitive or superior accuracy compared to existing neural and LLM-based baselines, and correctly selects numerical schemes based on PDE structural properties, suggesting its viability as an accessible paradigm for automated PDE solving.", "AI": {"tldr": "AutoNumerics is a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for PDEs from natural language descriptions, generating transparent solvers grounded in classical numerical analysis rather than black-box neural approaches.", "motivation": "Traditional PDE solver design requires substantial mathematical expertise and manual tuning, while recent neural network approaches suffer from high computational costs and limited interpretability. There's a need for accessible, automated PDE solving that maintains transparency and mathematical grounding.", "method": "Multi-agent framework with coarse-to-fine execution strategy and residual-based self-verification mechanism. The system autonomously designs, implements, debugs, and verifies numerical solvers from natural language PDE descriptions, generating transparent solvers based on classical numerical analysis principles.", "result": "Experiments on 24 canonical and real-world PDE problems show competitive or superior accuracy compared to existing neural and LLM-based baselines. The framework correctly selects numerical schemes based on PDE structural properties.", "conclusion": "AutoNumerics demonstrates viability as an accessible paradigm for automated PDE solving, offering transparent, mathematically-grounded solvers while maintaining competitive performance with existing approaches."}}
{"id": "2602.17663", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17663", "abs": "https://arxiv.org/abs/2602.17663", "authors": ["Juri Opitz", "Corina Racl\u00e9", "Emanuela Boros", "Andrianos Michail", "Matteo Romanello", "Maud Ehrmann", "Simon Clematide"], "title": "CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts", "comment": "ECIR 2026. CLEF Evaluation Lab. Registration DL: 2026/04/23. Task Homepage at https://hipe-eval.github.io/HIPE-2026/", "summary": "HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ (\"Has the person ever been at this place?\") and $isAt$ (\"Is the person located at this place around publication time?\") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.", "AI": {"tldr": "HIPE-2026 is a CLEF evaluation lab focusing on extracting person-place relations from historical texts, extending previous campaigns to include semantic relation extraction with temporal reasoning.", "motivation": "To advance historical text processing by moving beyond named entity recognition to semantic relation extraction, enabling downstream applications in digital humanities such as knowledge-graph construction, biography reconstruction, and spatial analysis.", "method": "A CLEF evaluation lab framework with multilingual, multi-temporal datasets; systems must classify two relation types ($at$ and $isAt$) requiring temporal and geographical reasoning; introduces three-fold evaluation assessing accuracy, computational efficiency, and domain generalization.", "result": "The lab establishes a benchmark for person-place relation extraction from historical texts, providing evaluation metrics and datasets for system comparison across languages and time periods.", "conclusion": "HIPE-2026 advances historical text processing by introducing semantic relation extraction challenges, creating infrastructure for evaluating systems on noisy historical data, and supporting digital humanities applications through relation extraction capabilities."}}
